{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "from services.app_api.features.extractor import FeatureExtractor\n",
    "from services.app_api.features.final_processing import CustomColumnTransformer\n",
    "from services.app_api.configs import utils, settings\n",
    "from tuning.optuna_tuning import OptunaTuner\n",
    "import optuna\n",
    "import wandb\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, ConfusionMatrixDisplay, make_scorer\n",
    "# Base classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier, Booster, DMatrix\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "# Meta classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    customers, sales = joblib.load('customers.joblib'), joblib.load('sales.joblib')\n",
    "except:\n",
    "    customers, sales = pd.read_excel('ucy_eko_data.xlsx', sheet_name='smile_customers'), pd.read_excel('ucy_eko_data.xlsx', sheet_name='smile_sales')\n",
    "    joblib.dump(customers, 'customers.joblib')\n",
    "    joblib.dump(sales, 'sales.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = FeatureExtractor(target_month=3, n_purchases=2, perform_split=True, generation_type='continuous', filtering_set='customers', period=60, subperiod=15)\n",
    "X_train, X_test, y_train, y_test = fe.transform(sales=sales, customers=customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_average_weighted = partial(f1_score, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_to_txt(optuna_object):\n",
    "    model = optuna_object.model\n",
    "    model_name = model.__str__()[:model.__str__().find('(')]\n",
    "    best_params = model.get_params()\n",
    "    with open(f'{model_name}.txt', 'w') as f:\n",
    "        f.write(json.dumps(best_params, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params(model):\n",
    "    try:\n",
    "        model = model()\n",
    "    except TypeError:\n",
    "        pass\n",
    "    model_name = model.__str__()[:model.__str__().find('(')]\n",
    "    with open(f'{model_name}.txt', 'r') as f:\n",
    "        params = json.loads(f.read())\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_op = OptunaTuner(\n",
    "#     SVC,\n",
    "#     accuracy_score,\n",
    "#     direction='maximize',\n",
    "#     random_state=571,\n",
    "#     verbose=False,\n",
    "#     tol=1\n",
    "# )\n",
    "# svc_op.fit(\n",
    "#     50, X_train_trans, y_train, X_test_trans, y_test,\n",
    "#     ('C', 'float', 1e-3, 1.0),\n",
    "#     ('kernel', 'categorical', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "#     ('degree', 'int', 1, 15)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna.visualization.plot_optimization_history(svc_op.study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_op.model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_best = SVC(\n",
    "    verbose=False,\n",
    "    random_state=571,\n",
    "    tol=1,\n",
    "    probability=True\n",
    ")\n",
    "svc_best.fit(X_train, y_train)\n",
    "svc_train_preds = svc_best.predict(X_train)\n",
    "svc_test_preds = svc_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:')\n",
    "print(classification_report(y_train, svc_train_preds), '\\n')\n",
    "print('Test:')\n",
    "print(classification_report(y_test, svc_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_op = OptunaTuner(\n",
    "    KNeighborsClassifier,\n",
    "    f1_score_average_weighted,\n",
    "    direction='maximize',\n",
    "    n_jobs=7\n",
    ")\n",
    "knn_op.fit(\n",
    "    100, X_train, y_train, X_test, y_test,\n",
    "    ('n_neighbors', 'int', 1, 50)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(knn_op.study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     knn_best_params = load_params(KNeighborsClassifier)\n",
    "#     knn_best = KNeighborsClassifier(**knn_best_params)\n",
    "# except FileNotFoundError:\n",
    "knn_best = KNeighborsClassifier(**knn_op.model.get_params())\n",
    "knn_best.fit(X_train, y_train)\n",
    "knn_train_preds = knn_best.predict(X_train)\n",
    "knn_test_preds = knn_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:')\n",
    "print(classification_report(y_train, knn_train_preds), '\\n')\n",
    "print('Test:')\n",
    "print(classification_report(y_test, knn_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_txt(knn_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_op = OptunaTuner(RandomForestClassifier, f1_score_average_weighted, direction='maximize', random_state=571, n_jobs=7)\n",
    "rf_op.fit(\n",
    "    100, X_train, y_train, X_test, y_test,\n",
    "    ('n_estimators', 'int', 10, 200),\n",
    "    ('max_depth', 'int', 30, 60),\n",
    "    ('max_features', 'float', 0.05, 1.0, {'step': 0.05}),\n",
    "    ('max_samples', 'float', 0.05, 1.0, {'step': 0.05}),\n",
    "    ('min_samples_leaf', 'float', 1e-4, 1e-2, {'log': True}),\n",
    "    ('min_samples_split', 'float', 1e-4, 1e-2, {'log': True})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     rf_best_params = load_params(RandomForestClassifier)\n",
    "#     rf_best = RandomForestClassifier(**rf_best_params)\n",
    "# except FileNotFoundError:\n",
    "rf_best = RandomForestClassifier(**rf_op.model.get_params())\n",
    "rf_best.fit(X_train, y_train)\n",
    "rf_train_preds = rf_best.predict(X_train)\n",
    "rf_test_preds = rf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:')\n",
    "print(classification_report(y_train, rf_train_preds), '\\n')\n",
    "print('Test:')\n",
    "print(classification_report(y_test, rf_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_txt(rf_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_op = OptunaTuner(\n",
    "    XGBClassifier, f1_score_average_weighted, 'maximize', # class-specific arguments\n",
    "    seed=571, predictor='cpu_predictor', verbosity=0, nthread=7, # model-specific technical parameters\n",
    "    objective='binary:logistic', eval_metric='error', n_estimators=1000 # model-specific fixed hyperparameters\n",
    ")\n",
    "xgb_op.fit(\n",
    "    100, X_train, y_train, X_test, y_test,\n",
    "    ('reg_alpha', 'loguniform', 1e-3, 10.0),\n",
    "    ('reg_lambda', 'loguniform', 1e-3, 10.0),\n",
    "    ('colsample_bytree', 'loguniform', 0.2, 1.0),\n",
    "    ('subsample', 'loguniform', 0.4, 1.0),\n",
    "    ('learning_rate', 'loguniform', 1e-4, 0.5),\n",
    "    ('max_depth', 'categorical', [5, 10, 20, 30])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    xgb_best_params = load_params(XGBClassifier)\n",
    "    xgb_best_params['objective'] = 'binary:logistic'\n",
    "    xgb_best = XGBClassifier(**xgb_best_params)\n",
    "except FileNotFoundError:\n",
    "    xgb_best = XGBClassifier(**xgb_op.model.get_params())\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_train_preds = xgb_best.predict(X_train)\n",
    "xgb_test_preds = xgb_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yaml\n",
    "# with open('service/app_api/api_config.yaml', 'rb') as f:\n",
    "#     config = yaml.safe_load(f)\n",
    "# classification_model_artifact = utils.get_artifact(config['wandb_classification_model_project'], f\"{config['wandb_classification_model_id']}_model.json\")\n",
    "# classification_model_artifact.download(config['model_path'])\n",
    "# classification_model = XGBClassifier()\n",
    "# classification_model.load_model(config['model_path']+f\"/{config['wandb_classification_model_id']}_model.json\")\n",
    "# classification_model.fit(X_train, y_train)\n",
    "# xgb_train_preds = classification_model.predict(X_train)\n",
    "# xgb_test_preds = classification_model.predict(X_test)\n",
    "# print('Train:')\n",
    "# print(classification_report(y_train, xgb_train_preds), '\\n')\n",
    "# print('Test:')\n",
    "# print(classification_report(y_test, xgb_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:')\n",
    "print(classification_report(y_train, xgb_train_preds), '\\n')\n",
    "print('Test:')\n",
    "print(classification_report(y_test, xgb_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best.feature_names_in_[0][:xgb_best.feature_names_in_[0].rindex('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "importance = pd.DataFrame({'feature': xgb_best.feature_names_in_, 'importance': xgb_best.feature_importances_})\n",
    "importance['feature'] = importance['feature'].apply(lambda x: x[:x.rindex('_')])\n",
    "importance['feature'] = importance['feature'].apply(lambda x: np.nan if 'previous' in x else x)\n",
    "importance.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.groupby('feature').sum().sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_txt(xgb_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, xgb_test_preds)\n",
    "cm_disp = ConfusionMatrixDisplay(cm, display_labels=xgb_best.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = xgb_op.model.get_params()\n",
    "    features = xgb_op.model.get_booster().feature_names\n",
    "except NameError:\n",
    "    config = xgb_best_params\n",
    "    xgb_best_params['objective'] = 'binary:logistic'\n",
    "    features = xgb_best.get_booster().feature_names\n",
    "\n",
    "# Create w&b run for the training set\n",
    "with utils.init_wandb_run(\n",
    "    name=f'continuous_features_subperiod_{fe.subperiod}_customers_filtering_{fe.n_purchases}_visits',\n",
    "    model=XGBClassifier,\n",
    "    config=config,\n",
    "    target_month=fe.target_month,\n",
    "    group='parameters_tuning',\n",
    "    job_type='tuning_train'\n",
    ") as run:\n",
    "    xgb_best = XGBClassifier(**xgb_best_params)\n",
    "    xgb_best.fit(X_train, y_train, callbacks=[wandb.xgboost.WandbCallback(log_model=True)])\n",
    "\n",
    "    rep = utils.parse_classification_report(\n",
    "        classification_report(y_train, xgb_train_preds, output_dict=True)\n",
    "    )\n",
    "\n",
    "    metadata = {\n",
    "        'experiment': {\n",
    "            'name': run.name,\n",
    "        },\n",
    "        'performance_report': rep,\n",
    "        'features': features\n",
    "    }\n",
    "\n",
    "    artifact = wandb.Artifact(\n",
    "        name=f'report_train',\n",
    "        type='performance_metric',\n",
    "        metadata=metadata\n",
    "    )\n",
    "    run.log_artifact(artifact)\n",
    "    run.finish()\n",
    "\n",
    "# Create w&b run for the test set\n",
    "with utils.init_wandb_run(\n",
    "    name=f'continuous_features_subperiod_{fe.subperiod}_customers_filtering_{fe.n_purchases}_visits',\n",
    "    model=XGBClassifier,\n",
    "    config=config,\n",
    "    target_month=fe.target_month,\n",
    "    group='parameters_tuning',\n",
    "    job_type='tuning_test'\n",
    ") as run:\n",
    "    rep = utils.parse_classification_report(\n",
    "        classification_report(y_test, xgb_test_preds, output_dict=True)\n",
    "    )\n",
    "\n",
    "    metadata = {\n",
    "        'experiment': {\n",
    "            'name': run.name\n",
    "        },\n",
    "        'performance_report': rep,\n",
    "        'features': features\n",
    "    }\n",
    "\n",
    "    artifact = wandb.Artifact(\n",
    "        name=f'report_test',\n",
    "        type='performance_metric',\n",
    "        metadata=metadata\n",
    "    )\n",
    "    run.log_artifact(artifact)\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_api = wandb.Api()\n",
    "model_run = wandb_api.run(f\"{settings.SETTINGS['WANDB_ENTITY']}/X-G-B-Classifier/gnazdw35\")\n",
    "model_config = json.loads(model_run.json_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art = utils.get_artifact('X-G-B-Classifier', '00g8kx9u_model.json')\n",
    "art.download('service/app_api/configs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_json_loaded = XGBClassifier()\n",
    "xgb_json_loaded.load_model('service/app_api/configs/gnazdw35_model.json')\n",
    "xgb_train_preds = xgb_json_loaded.predict(X_train)\n",
    "xgb_test_preds = xgb_json_loaded.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:')\n",
    "print(classification_report(y_train, xgb_train_preds), '\\n')\n",
    "print('Test:')\n",
    "print(classification_report(y_test, xgb_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(xgb_json_loaded)\n",
    "shapley_values = explainer.shap_values(X_train.head(1), y_train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify overlaps of models errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models_df = pd.DataFrame(\n",
    "    {\n",
    "        'svc_preds': svc_test_preds,\n",
    "        'knn_preds': knn_test_preds,\n",
    "        'rf_preds': rf_test_preds,\n",
    "        'xgb_preds': xgb_test_preds,\n",
    "        'y_true': y_test\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models_df['svc_accuracy'] = base_models_df.apply(lambda x: 'error' if x['svc_preds'] != x['y_true'] else 'correct', axis=1)\n",
    "base_models_df['knn_accuracy'] = base_models_df.apply(lambda x: 'error' if x['knn_preds'] != x['y_true'] else 'correct', axis=1)\n",
    "base_models_df['rf_accuracy'] = base_models_df.apply(lambda x: 'error' if x['rf_preds'] != x['y_true'] else 'correct', axis=1)\n",
    "base_models_df['xgb_accuracy'] = base_models_df.apply(lambda x: 'error' if x['xgb_preds'] != x['y_true'] else 'correct', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_errors = base_models_df[base_models_df['svc_accuracy']=='error'].index\n",
    "knn_errors = base_models_df[base_models_df['knn_accuracy']=='error'].index\n",
    "rf_errors = base_models_df[base_models_df['rf_accuracy']=='error'].index\n",
    "xgb_errors = base_models_df[base_models_df['xgb_accuracy']=='error'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlap of all models\n",
    "len(\n",
    "    set.intersection(\n",
    "        set(svc_errors),\n",
    "        set(knn_errors),\n",
    "        set(rf_errors),\n",
    "        set(xgb_errors)\n",
    "    )\n",
    ") / base_models_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\n",
    "    set.intersection(\n",
    "        set(rf_errors),\n",
    "        set(xgb_errors)\n",
    "    )\n",
    ") / base_models_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('svc', svc_best),\n",
    "        ('knn', knn_best),\n",
    "        ('rf', rf_best),\n",
    "        ('xgb', xgb_best)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model.fit(X_train, y_train)\n",
    "stacking_train_preds = stacking_model.predict(X_train)\n",
    "stacking_test_preds = stacking_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:')\n",
    "print(classification_report(y_train, stacking_train_preds), '\\n')\n",
    "print('Test:')\n",
    "print(classification_report(y_test, stacking_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_stacking_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svc', svc_best),\n",
    "        ('knn', knn_best),\n",
    "        ('rf', rf_best),\n",
    "        ('xgb', xgb_best)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    n_jobs=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_stacking_model.fit(X_train, y_train)\n",
    "voting_stacking_train_preds = voting_stacking_model.predict(X_train)\n",
    "voting_stacking_test_preds = voting_stacking_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:')\n",
    "print(classification_report(y_train, voting_stacking_train_preds), '\\n')\n",
    "print('Test:')\n",
    "print(classification_report(y_test, voting_stacking_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'weights': [\n",
    "        (1, 1, 3, 3),\n",
    "        (1, 1, 2, 3),\n",
    "        (1, 1, 3, 4),\n",
    "        (1, 1, 2, 5),\n",
    "        (1, 2, 2, 3),\n",
    "        (1, 2, 3, 4),\n",
    "        (1, 2, 3, 3)\n",
    "    ]\n",
    "}\n",
    "grid = GridSearchCV(\n",
    "    estimator=voting_stacking_model,\n",
    "    param_grid=params,\n",
    "    n_jobs=7,\n",
    "    cv=5,\n",
    "    scoring=make_scorer(f1_score, **{'average': 'weighted'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_voting_stacking_train_preds = grid.predict(X_train)\n",
    "tuned_voting_stacking_test_preds = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:')\n",
    "print(classification_report(y_train, tuned_voting_stacking_train_preds), '\\n')\n",
    "print('Test:')\n",
    "print(classification_report(y_test, tuned_voting_stacking_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
