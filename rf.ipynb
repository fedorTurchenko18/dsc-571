{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: /Users/grigoryturchenko/.netrc\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, wandb, warnings, optuna, joblib\n",
    "warnings.filterwarnings('ignore')\n",
    "from features.extractor import FeatureExtractor\n",
    "from features.final_processing import CustomColumnTransformer\n",
    "from tuning.optuna_tuning import OptunaTuner\n",
    "from configs import utils\n",
    "utils.login_wandb()\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    customers, sales = joblib.load('customers.joblib'), joblib.load('sales.joblib')\n",
    "except:\n",
    "    customers, sales = pd.read_excel('ucy_eko_data.xlsx', sheet_name='smile_customers'), pd.read_excel('ucy_eko_data.xlsx', sheet_name='smile_sales')\n",
    "    joblib.dump(customers, 'customers.joblib')\n",
    "    joblib.dump(sales, 'sales.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/grigoryturchenko/.cache/huggingface/token\n",
      "Login successful\n",
      "Successfully logged out.\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureExtractor(sales=sales, customers=customers, target_month=3, perform_split=True, generation_type='continuous', filtering_set='sales', period=60, subperiod=15)\n",
    "X_train, X_test, y_train, y_test = fe.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qty_cols = [col for col in X_train.columns if 'qty' in col]\n",
    "col_transform = CustomColumnTransformer(\n",
    "    cols_for_scaling=qty_cols,\n",
    "    scaling_algo=RobustScaler(),\n",
    "    cols_for_ohe=None,\n",
    "    cols_for_winsor=None,\n",
    "    cols_to_skip=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('column_transformer', col_transform),\n",
    "        ('rf', RandomForestClassifier(max_features=None, random_state=571, n_jobs=7))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     25669\n",
      "           1       1.00      0.98      0.99     29752\n",
      "\n",
      "    accuracy                           0.98     55421\n",
      "   macro avg       0.98      0.98      0.98     55421\n",
      "weighted avg       0.98      0.98      0.98     55421\n",
      "\n",
      "Test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.74      8603\n",
      "           1       0.78      0.77      0.77      9871\n",
      "\n",
      "    accuracy                           0.76     18474\n",
      "   macro avg       0.76      0.76      0.76     18474\n",
      "weighted avg       0.76      0.76      0.76     18474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "train_preds = pipe.predict(X_train)\n",
    "test_preds = pipe.predict(X_test)\n",
    "\n",
    "print('Train data')\n",
    "print(classification_report(y_train, train_preds))\n",
    "print('Test data')\n",
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = col_transform.fit_transform(X_train, y_train), col_transform.fit_transform(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_op = OptunaTuner(RandomForestClassifier, accuracy_score, direction='maximize', random_state=571, n_jobs=7)\n",
    "rf_op.fit(\n",
    "    200, X_train, y_train, X_test, y_test,\n",
    "    ('n_estimators', 'int', 10, 200),\n",
    "    ('max_depth', 'int', 20, 40),\n",
    "    ('max_features', 'float', 0.05, 1.0, {'step': 0.05}),\n",
    "    ('max_samples', 'float', 0.05, 1.0, {'step': 0.05}),\n",
    "    ('min_samples_leaf', 'float', 1e-4, 1e-2, {'log': True}),\n",
    "    ('min_samples_split', 'float', 1e-4, 1e-2, {'log': True})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 21,\n",
       " 'max_features': 0.1,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': 0.4,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 0.000627318769493311,\n",
       " 'min_samples_split': 0.00155668115409059,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 77,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_op.model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199
         ],
         "y": [
          0.7751975749702285,
          0.7770379993504385,
          0.7742773627801234,
          0.7745480134242719,
          0.7754140954855473,
          0.7746562736819314,
          0.7733030204611887,
          0.7663743639709862,
          0.7753058352278879,
          0.7740608422648045,
          0.7740067121359748,
          0.7756306160008661,
          0.7763343076756523,
          0.7738984518783155,
          0.7737901916206561,
          0.7749810544549096,
          0.7734112807188481,
          0.7742773627801234,
          0.7744397531666125,
          0.7752517050990582,
          0.7748186640684205,
          0.7693515210566201,
          0.7744397531666125,
          0.7742232326512937,
          0.7761719172891631,
          0.7737360614918264,
          0.7742773627801234,
          0.7759012666450146,
          0.7757388762585254,
          0.7756847461296957,
          0.7749810544549096,
          0.775089314712569,
          0.7754140954855473,
          0.7763343076756523,
          0.7751434448413987,
          0.7762260474179928,
          0.7751975749702285,
          0.7772545198657573,
          0.7755764858720364,
          0.7769838692216088,
          0.7749810544549096,
          0.7774169102522464,
          0.7753599653567176,
          0.7762260474179928,
          0.7747645339395908,
          0.7743856230377828,
          0.7741149723936342,
          0.7724369383999133,
          0.7727075890440619,
          0.7705965140197034,
          0.7733030204611887,
          0.7753599653567176,
          0.7754140954855473,
          0.7744397531666125,
          0.771029555050341,
          0.7751434448413987,
          0.7759553967738443,
          0.776009526902674,
          0.7776875608963949,
          0.7762801775468225,
          0.7767673487062899,
          0.7769297390927791,
          0.7763343076756523,
          0.7768756089639494,
          0.776388437804482,
          0.7743856230377828,
          0.7743856230377828,
          0.7717873768539569,
          0.7765508281909711,
          0.7712460755656598,
          0.7751975749702285,
          0.7751434448413987,
          0.7751434448413987,
          0.7751434448413987,
          0.7716791165962975,
          0.7714625960809787,
          0.7716791165962975,
          0.7756847461296957,
          0.7764966980621414,
          0.7764425679333117,
          0.7761719172891631,
          0.7759553967738443,
          0.7767673487062899,
          0.7769838692216088,
          0.7768214788351196,
          0.7762260474179928,
          0.7762801775468225,
          0.7758471365161849,
          0.7764966980621414,
          0.7769297390927791,
          0.7766590884486305,
          0.776388437804482,
          0.776388437804482,
          0.7755764858720364,
          0.7746021435531016,
          0.7748186640684205,
          0.776009526902674,
          0.7756847461296957,
          0.7763343076756523,
          0.7756847461296957,
          0.7718956371116164,
          0.7762260474179928,
          0.7764425679333117,
          0.7740608422648045,
          0.7748727941972502,
          0.775089314712569,
          0.7730864999458699,
          0.7767132185774602,
          0.7764425679333117,
          0.7734112807188481,
          0.7717873768539569,
          0.7758471365161849,
          0.7768214788351196,
          0.7767673487062899,
          0.7766049583198008,
          0.776388437804482,
          0.7766590884486305,
          0.7762260474179928,
          0.7764425679333117,
          0.7759012666450146,
          0.7731406300746996,
          0.7759553967738443,
          0.7754140954855473,
          0.7756306160008661,
          0.7735195409765075,
          0.7727617191728916,
          0.7753599653567176,
          0.7759553967738443,
          0.7752517050990582,
          0.7751434448413987,
          0.7770379993504385,
          0.7769838692216088,
          0.7751975749702285,
          0.7769297390927791,
          0.7767673487062899,
          0.7772545198657573,
          0.7772003897369276,
          0.7770921294792682,
          0.7769297390927791,
          0.7767132185774602,
          0.7766590884486305,
          0.771408465952149,
          0.7722204178845946,
          0.7716249864674678,
          0.7727617191728916,
          0.772869979430551,
          0.776388437804482,
          0.7765508281909711,
          0.7711919454368301,
          0.773627801234167,
          0.7770921294792682,
          0.776009526902674,
          0.7774710403810761,
          0.7768214788351196,
          0.7777416910252246,
          0.7775251705099058,
          0.777308649994587,
          0.7774169102522464,
          0.7759012666450146,
          0.7763343076756523,
          0.7751975749702285,
          0.775089314712569,
          0.7772003897369276,
          0.7756847461296957,
          0.7745480134242719,
          0.7743856230377828,
          0.7744397531666125,
          0.7743314929089531,
          0.7761177871603334,
          0.7777416910252246,
          0.7711919454368301,
          0.771029555050341,
          0.7716791165962975,
          0.7766590884486305,
          0.7766590884486305,
          0.7770379993504385,
          0.7766590884486305,
          0.7761719172891631,
          0.7772003897369276,
          0.7767673487062899,
          0.7766590884486305,
          0.776388437804482,
          0.7761177871603334,
          0.7772003897369276,
          0.7768756089639494,
          0.7740067121359748,
          0.7724369383999133,
          0.773248890332359,
          0.7742232326512937,
          0.7717873768539569,
          0.7696763018295983,
          0.7731947602035293,
          0.7743314929089531,
          0.7743314929089531,
          0.7747645339395908,
          0.7738984518783155,
          0.7760636570315037,
          0.7753058352278879,
          0.775468225614377,
          0.7750351845837393
         ]
        },
        {
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199
         ],
         "y": [
          0.7751975749702285,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7770379993504385,
          0.7772545198657573,
          0.7772545198657573,
          0.7772545198657573,
          0.7772545198657573,
          0.7774169102522464,
          0.7774169102522464,
          0.7774169102522464,
          0.7774169102522464,
          0.7774169102522464,
          0.7774169102522464,
          0.7774169102522464,
          0.7774169102522464,
          0.7774169102522464,
          0.7774169102522464,
          0.7774169102522464,
          0.7774169102522464,
          0.7774169102522464,
          0.7774169102522464,
          0.7774169102522464,
          0.7774169102522464,
          0.7774169102522464,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7776875608963949,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246,
          0.7777416910252246
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(rf_op.study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'bootstrap': True,\n",
    " 'ccp_alpha': 0.0,\n",
    " 'class_weight': None,\n",
    " 'criterion': 'gini',\n",
    " 'max_depth': 36,\n",
    " 'max_features': 0.1,\n",
    " 'max_leaf_nodes': None,\n",
    " 'max_samples': 0.9000000000000001,\n",
    " 'min_impurity_decrease': 0.0,\n",
    " 'min_samples_leaf': 0.003570132806941135,\n",
    " 'min_samples_split': 0.004948383139887321,\n",
    " 'min_weight_fraction_leaf': 0.0,\n",
    " 'n_estimators': 163,\n",
    " 'n_jobs': None,\n",
    " 'oob_score': False,\n",
    " 'random_state': None,\n",
    " 'verbose': 0,\n",
    " 'warm_start': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgaturchenko\u001b[0m (\u001b[33mkpmg-capstone\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/grigoryturchenko/Docs/UCY/dsc-571/wandb/run-20230801_153221-nx2p98su</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kpmg-capstone/Random-Forest-Classifier/runs/nx2p98su' target=\"_blank\">continuous_features_optuna_subperiod_15_month3_2023-08-01_15-32-17</a></strong> to <a href='https://wandb.ai/kpmg-capstone/Random-Forest-Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kpmg-capstone/Random-Forest-Classifier' target=\"_blank\">https://wandb.ai/kpmg-capstone/Random-Forest-Classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kpmg-capstone/Random-Forest-Classifier/runs/nx2p98su' target=\"_blank\">https://wandb.ai/kpmg-capstone/Random-Forest-Classifier/runs/nx2p98su</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">continuous_features_optuna_subperiod_15_month3_2023-08-01_15-32-17</strong> at: <a href='https://wandb.ai/kpmg-capstone/Random-Forest-Classifier/runs/nx2p98su' target=\"_blank\">https://wandb.ai/kpmg-capstone/Random-Forest-Classifier/runs/nx2p98su</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230801_153221-nx2p98su/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/grigoryturchenko/Docs/UCY/dsc-571/wandb/run-20230801_153233-0hznug8a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kpmg-capstone/Random-Forest-Classifier/runs/0hznug8a' target=\"_blank\">continuous_features_optuna_subperiod_15_month3_2023-08-01_15-32-33</a></strong> to <a href='https://wandb.ai/kpmg-capstone/Random-Forest-Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kpmg-capstone/Random-Forest-Classifier' target=\"_blank\">https://wandb.ai/kpmg-capstone/Random-Forest-Classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kpmg-capstone/Random-Forest-Classifier/runs/0hznug8a' target=\"_blank\">https://wandb.ai/kpmg-capstone/Random-Forest-Classifier/runs/0hznug8a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">continuous_features_optuna_subperiod_15_month3_2023-08-01_15-32-33</strong> at: <a href='https://wandb.ai/kpmg-capstone/Random-Forest-Classifier/runs/0hznug8a' target=\"_blank\">https://wandb.ai/kpmg-capstone/Random-Forest-Classifier/runs/0hznug8a</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230801_153233-0hznug8a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "    'bootstrap': True,\n",
    "    'ccp_alpha': 0.0,\n",
    "    'class_weight': None,\n",
    "    'criterion': 'gini',\n",
    "    'max_depth': 36,\n",
    "    'max_features': 0.1,\n",
    "    'max_leaf_nodes': None,\n",
    "    'max_samples': 0.9000000000000001,\n",
    "    'min_impurity_decrease': 0.0,\n",
    "    'min_samples_leaf': 0.003570132806941135,\n",
    "    'min_samples_split': 0.004948383139887321,\n",
    "    'min_weight_fraction_leaf': 0.0,\n",
    "    'n_estimators': 163,\n",
    "    'n_jobs': None,\n",
    "    'oob_score': False,\n",
    "    'random_state': None,\n",
    "    'verbose': 0,\n",
    "    'warm_start': False\n",
    "}\n",
    "rf = RandomForestClassifier(**config)\n",
    "\n",
    "# Create w&b run for the training set\n",
    "with utils.init_wandb_run(\n",
    "    name='continuous_features_optuna_subperiod_15',\n",
    "    model=RandomForestClassifier,\n",
    "    config=config,\n",
    "    target_month=fe.target_month,\n",
    "    group='parameters_tuning',\n",
    "    job_type='tuning_train'\n",
    ") as run:\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    train_preds = rf.predict(X_train)\n",
    "\n",
    "    rep = utils.parse_classification_report(\n",
    "        classification_report(y_train, train_preds, output_dict=True)\n",
    "    )\n",
    "\n",
    "    metadata = {\n",
    "        'experiment': {\n",
    "            'name': run.name,\n",
    "        },\n",
    "        'performance_report': rep,\n",
    "        'config': config\n",
    "    }\n",
    "\n",
    "    artifact = wandb.Artifact(\n",
    "        name=f'report_train',\n",
    "        type='performance_metric',\n",
    "        metadata=metadata\n",
    "    )\n",
    "    run.log_artifact(artifact)\n",
    "    run.finish()\n",
    "\n",
    "# Create w&b run for the test set\n",
    "with utils.init_wandb_run(\n",
    "    name='continuous_features_optuna_subperiod_15',\n",
    "    model=RandomForestClassifier,\n",
    "    config=config,\n",
    "    target_month=fe.target_month,\n",
    "    group='parameters_tuning',\n",
    "    job_type='tuning_test'\n",
    ") as run:\n",
    "    test_preds = rf.predict(X_test)\n",
    "    rep = utils.parse_classification_report(\n",
    "        classification_report(y_test, test_preds, output_dict=True)\n",
    "    )\n",
    "\n",
    "    metadata = {\n",
    "        'experiment': {\n",
    "            'name': run.name,\n",
    "        },\n",
    "        'performance_report': rep,\n",
    "        'config': config\n",
    "    }\n",
    "\n",
    "    artifact = wandb.Artifact(\n",
    "        name=f'report_test',\n",
    "        type='performance_metric',\n",
    "        metadata=metadata\n",
    "    )\n",
    "    run.log_artifact(artifact)\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
