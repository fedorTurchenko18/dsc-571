{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from services.app_api.features.extractor import FeatureExtractor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from yellowbrick.cluster.elbow import KElbowVisualizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy.stats.mstats import winsorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customers, sales = pd.read_excel('ucy_eko_data.xlsx', sheet_name='smile_customers'), pd.read_excel('ucy_eko_data.xlsx', sheet_name='smile_sales')\n",
    "customers, sales = joblib.load('customers.joblib'), joblib.load('sales.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = FeatureExtractor(target_month=3, perform_split=False, period=60, subperiod=60, generation_type='continuous', filtering_set='customers')\n",
    "X, y = fe.transform(sales=sales, customers=customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'fuel_qty_1-60'\n",
    "s[:s.find('_1-60')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns = [f'{col[:col.find(\"_1-60\")]}' for col in X.columns]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_clust = X[X['monetary']<=1000][['monetary', 'recency', 'average_days_between_visits']]\n",
    "\n",
    "X_clust = X[['monetary', 'recency', 'average_days_between_visits']]\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "fig.add_axes(ax)\n",
    "\n",
    "cmap = ListedColormap(sns.color_palette('husl', 256).as_hex())\n",
    "\n",
    "sc = ax.scatter(X_clust['monetary'], X_clust['recency'], X_clust['average_days_between_visits'], s=40, c=X_clust['monetary'], marker='o', cmap=cmap, alpha=1)\n",
    "ax.set_xlabel('Total Spending\\nDuring the First Month (\"Monetary\")', labelpad=20)\n",
    "ax.set_ylabel('Average Days between Visits\\nDuring the First Month (\"Frequency\")', labelpad=20)\n",
    "ax.set_zlabel('Difference between\\nthe Ending Date of the First Month\\nand Latest Purchase (\"Recency\")', labelpad=20)\n",
    "\n",
    "ax.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot shows extreme outliers for the Monetary variable. Let us examine 99th percentile of this variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"99th percentile: {X_clust['monetary'].quantile(0.99)}\")\n",
    "print(f\"Maximum: {X_clust['monetary'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the 99th percentile differs from the maximum value, it makes sense to winsorize these outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winsor = winsorize(X['monetary'], limits=(0.0, 0.01))\n",
    "with open('service/app_api/features/winsorizing_object_for_threshold.pkl', 'wb') as f:\n",
    "    pickle.dump(winsor, f)\n",
    "X_clust['monetary'] = winsor\n",
    "X_clust['monetary'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now examine the plot again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "fig.add_axes(ax)\n",
    "\n",
    "cmap = ListedColormap(sns.color_palette(\"husl\", 256).as_hex())\n",
    "\n",
    "sc = ax.scatter(X_clust['monetary'], X_clust['recency'], X_clust['average_days_between_visits'], s=40, c=X_clust['monetary'], marker='o', cmap=cmap, alpha=1)\n",
    "ax.set_xlabel('Total Spending\\nDuring the First Month (\"Monetary\")', labelpad=20)\n",
    "ax.set_ylabel('Average Days between Visits\\nDuring the First Month (\"Frequency\")', labelpad=20)\n",
    "ax.set_zlabel('Difference between\\nthe Ending Date of the First Month\\nand Latest Purchase (\"Recency\")', labelpad=20)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the plot, one may consider that 3 or 4 clusters could be optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clust = StandardScaler().fit_transform(X_clust)\n",
    "model = KMeans()\n",
    "elbow_viz = KElbowVisualizer(model, k=(1, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbow_viz.fit(X_clust)\n",
    "elbow_viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elbow method suggests 4 clusters as the optimal value. Let us also compute silhoutte ccore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(2, 11):\n",
    "    model = KMeans(k)\n",
    "    labels = model.fit_predict(X_clust)\n",
    "    print(f'{k}: {silhouette_score(X_clust, labels)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best silhoutte score was also computed for 4 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 4\n",
    "best_model = KMeans(n_clusters=K, random_state=571)\n",
    "labels = best_model.fit_predict(X_clust)\n",
    "centroids = best_model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "df_clust = pd.DataFrame(tsne.fit_transform(X_clust), columns=['PC1','PC2'])\n",
    "df_clust['cluster'] = pd.Categorical(labels)\n",
    "\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='cluster', data=df_clust, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['cluster'] = pd.Categorical(labels).rename_categories(\n",
    "    {\n",
    "        0: 'Regular drivers',\n",
    "        1: 'Passerbys',\n",
    "        2: 'Frequent drivers',\n",
    "        3: 'At Churn Risk'\n",
    "    }\n",
    ")\n",
    "X['cluster'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['target'] = pd.Categorical(y).rename_categories(\n",
    "    {\n",
    "        0: 'No purchases at month 3',\n",
    "        1: 'At least 2 purchases at month 3'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.rename({'average_days_between_visits': 'frequency'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_agg = X.pivot_table(values=['monetary', 'recency', 'frequency'], columns=['target', 'cluster'], aggfunc=np.median).round(2)\n",
    "X_agg = X_agg.rename({i: i.capitalize() for i in X_agg.index.unique()}, axis=0)\n",
    "X_agg.columns.names = ['', 'Indicator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = []\n",
    "for i, j in X_agg.columns:\n",
    "    if j == 'Regular drivers':\n",
    "        new_cols.append(f\"{i}\\n{j}\")\n",
    "    else:\n",
    "        new_cols.append(j)\n",
    "X_agg.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_agg_json = {}\n",
    "for col_0 in X_agg.columns.get_level_values(0).unique():\n",
    "    X_agg_json[col_0] = [(X_agg[col_0].to_dict(orient='dict'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_agg_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('service/app_ui/shap_plots/segments_target_rfm_table.json', 'w') as f:\n",
    "    json.dump(X_agg_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('service/app_ui/shap_plots/segments_target_rfm_table.json') as data_file:    \n",
    "    d = json.load(data_file)  \n",
    "df = pd.concat({k: pd.DataFrame(v) for k, v in d.items()}).unstack(0).swaplevel(1,0, axis=1).sort_index(axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.groupby('cluster').agg(\n",
    "    Recency = pd.NamedAgg('recency', 'median'),\n",
    "    Frequency = pd.NamedAgg('frequency', 'median'),\n",
    "    Monetary = pd.NamedAgg('monetary', 'median')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regular drivers:\n",
    "    - medium spending\n",
    "    - medium recency\n",
    "    - medium frequency\n",
    "\n",
    "This cluster customers are quite loyal but, perhaps, not driving this much, so they do not need to visit gas stations often and pay much\n",
    "\n",
    "- Passerbys:\n",
    "    - lowest spending\n",
    "    - worst recency\n",
    "    - zero frequency\n",
    "\n",
    "This cluster represents users who made one-two visits and most likely left\n",
    "\n",
    "- Frequent drivers:\n",
    "    - highest spending\n",
    "    - best recency\n",
    "    - best frequency\n",
    "\n",
    "This cluster represents users who are frequently visiting gas stations, paying a lot. Perhaps, these are the most loyal customers who are driving long distances\n",
    "\n",
    "- At churn risk:\n",
    "    - low spending\n",
    "    - medium recency\n",
    "    - low frequency\n",
    "\n",
    "This cluster represents users who are visiting gas stations from time to time. They are not spending much, not making their visits often, so could be considered to be at risk of churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_agg.columns.get_level_values(0).replace()\n",
    "X_agg.columns.get_level_values(1).rename_categories(\n",
    "    {\n",
    "        0: 'Regular drivers',\n",
    "        1: 'Passerbys',\n",
    "        2: 'Frequent drivers',\n",
    "        3: 'At Churn Risk'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./features/clustering_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(best_model.labels_).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('services/app_api/features/clustering_model.pkl', 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        # Load `scipy.stats.mstats.winsorize` output object to define threshold for the `monetary` variable\n",
    "with open('services/app_api/configs/centroids_table.table.json', 'r') as f:\n",
    "    centroids_table = json.load(f)\n",
    "with open('services/app_api/features/winsorizing_object_for_threshold.pkl', 'rb') as f:\n",
    "    winsor = pickle.load(f)\n",
    "X_clust = X[['monetary', 'recency', 'average_days_between_visits']]\n",
    "monetary_threshold = winsor.max()\n",
    "# Perform winsorization\n",
    "X_clust.loc[X_clust['monetary'] > monetary_threshold, 'monetary'] = monetary_threshold\n",
    "scaler = StandardScaler()\n",
    "labels = pd.Categorical(\n",
    "    model.predict(\n",
    "        scaler.fit_transform(X_clust)\n",
    "    )\n",
    ")\n",
    "X['segments'] = labels\n",
    "X['segments'] = X['segments'].cat.rename_categories({3: 'at_churn_risk', 2: 'frequent_drivers', 1: 'passerbys', 0: 'regular_drivers'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "df_chart = X['segments'].value_counts().to_frame().reset_index()\n",
    "print(df_chart)\n",
    "df_chart['index'] = df_chart['index'].apply(lambda x: ' '.join([s.capitalize() for s in x.split('_')]))\n",
    "\n",
    "labels = df_chart['index']\n",
    "values = df_chart['segments']\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo='label+percent', textfont_size=20)])\n",
    "fig.update_layout(height=800, width=1200, title=dict(text=\"Eko Customers Distribution by Defined Segments\", font=dict(size=30)))\n",
    "fig.update(layout_showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chart = X['segments'].value_counts().to_frame()\n",
    "df_chart.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[['ciid', 'segments']].to_excel('user_segment_mapping.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "sample = X.loc[random.randint(0, X.index.max()), ['average_days_between_visits', 'recency', 'monetary']]\n",
    "dist = cdist(np.array(sample, ndmin=2), centroids, 'cosine')[0]\n",
    "sim = 1-dist\n",
    "label = labels[sample.name]\n",
    "print(label)\n",
    "print(dist)\n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sim+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from services.app_api.configs import utils, settings\n",
    "utils.login_wandb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.sklearn.plot_elbow_curve(best_model, X_clust)\n",
    "with utils.init_wandb_run(\n",
    "    name='rfm_features_clustering',\n",
    "    model=KMeans,\n",
    "    config=best_model.get_params(),\n",
    "    target_month=None,\n",
    "    group='clustering',\n",
    "    job_type='clustering_fit'\n",
    ") as run:\n",
    "    metadata = {\n",
    "        'experiment': {\n",
    "            'name': run.name,\n",
    "        }\n",
    "    }\n",
    "    artifact = wandb.Artifact(\n",
    "        name='clustering_report',\n",
    "        type='performance_metric',\n",
    "        metadata=metadata\n",
    "    )\n",
    "    artifact.add(wandb.Table(data=centroids, columns=['monetary', 'recency', 'average_days_between_visits']), name='centroids_table')\n",
    "    artifact.add(wandb.Table(columns=['monetary_winsorization_threshold'], data=[[monetary_threshold]]), name='monetary_winsorization_threshold')\n",
    "    run.log_artifact(artifact)\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = utils.get_artifact('K-Means', 'clustering_report')\n",
    "cm.download('service/app_api/configs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('service/app_api/configs/centroids_table.table.json', 'r') as f:\n",
    "    table = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.array(sample, ndmin=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[s[0][table['columns'].index('monetary')] > monetary_threshold] = monetary_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = StandardScaler().fit_transform(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = np.exp(-cdist(s, table['data'], 'euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim[0].tolist().index(sim.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_euc = []\n",
    "euc_dist_matrix = cdist(X_clust, centroids, 'euclidean')\n",
    "for row in euc_dist_matrix:\n",
    "    max_dist = row.min()\n",
    "    pred = row.tolist().index(max_dist)\n",
    "    labels_euc.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(labels == np.array(labels_euc)).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euc_dist_df = pd.DataFrame(euc_dist_matrix)\n",
    "euc_dist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euc_dist_df.apply(lambda x: np.exp(-x), axis=0).head()#.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = utils.get_artifact('K-Means', f\"clustering_report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.get('centroids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X.groupby('target')['labour_cards_catalogue_consumables'].value_counts(normalize=True)*100).apply(lambda x: f'{round(x, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.groupby('target')['labour_cards_catalogue_consumables_qty'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit_transform(X_clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "        0: 'Regular Drivers',\n",
    "        1: 'Passerbys',\n",
    "        2: 'Frequent Drivers',\n",
    "        3: 'At Churn Risk'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Generate sample data\n",
    "data = scaler.fit_transform(X_clust)\n",
    "\n",
    "# Create a 3D scatter plot using Plotly Graph Objects\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add scatter plot for each cluster\n",
    "for cluster_id, cluster_label in zip([i for i in range(max(labels) + 1)], ['Regular Drivers', 'Passerbys', 'Frequent Drivers', 'At Churn Risk']):\n",
    "    cluster_points = X_clust.to_numpy()[labels == cluster_id]\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=cluster_points[:, 0],\n",
    "        y=cluster_points[:, 1],\n",
    "        z=cluster_points[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(size=6),\n",
    "        # name=f'Cluster {cluster_id + 1}',\n",
    "        name=cluster_label,\n",
    "        opacity=0.1\n",
    "    ))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            title='Monetary',\n",
    "            tickmode='array',\n",
    "            tickvals=[0.0]+[float(i[i.find(', ')+len(', '):i.find(']')]) for i in pd.cut(scaler.inverse_transform(data)[:, 0], 5).categories.astype('str')],\n",
    "            ticktext=['0.0']+[i[i.find(', ')+len(', '):i.find(']')] for i in pd.cut(scaler.inverse_transform(data)[:, 0], 5).categories.astype('str')]\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Recency',\n",
    "            tickmode='array',\n",
    "            tickvals=[0.0]+[float(i[i.find(', ')+len(', '):i.find(']')]) for i in pd.cut(scaler.inverse_transform(data)[:, 1], 5).categories.astype('str')],\n",
    "            ticktext=['0.0']+[i[i.find(', ')+len(', '):i.find(']')] for i in pd.cut(scaler.inverse_transform(data)[:, 1], 5).categories.astype('str')]\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            title='Frequency',\n",
    "            tickmode='array',\n",
    "            tickvals=[0.0]+[float(i[i.find(', ')+len(', '):i.find(']')]) for i in pd.cut(scaler.inverse_transform(data)[:, 2], 5).categories.astype('str')],\n",
    "            ticktext=['0.0']+[i[i.find(', ')+len(', '):i.find(']')] for i in pd.cut(scaler.inverse_transform(data)[:, 2], 5).categories.astype('str')]\n",
    "        ),\n",
    "    ),\n",
    "    title='3D Plot of Clusters',\n",
    "    showlegend=True,\n",
    "    height=800,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "# Add scatter plot for cluster centers\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=scaler.inverse_transform(model.cluster_centers_)[:, 0],\n",
    "    y=scaler.inverse_transform(model.cluster_centers_)[:, 1],\n",
    "    z=scaler.inverse_transform(model.cluster_centers_)[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=10, color='yellow'),\n",
    "    name='Cluster Centers'\n",
    "))\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'ip-172-31-95-167.ec2.internal'\n",
    "s[s.find('-')+len('-'):s.find('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
