{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: /Users/fedorturchenko/.netrc\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wandb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from features.extractor import FeatureExtractor\n",
    "from configs import utils\n",
    "utils.login_wandb()\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Union\n",
    "def parse_classification_report(report: Union[Literal['sklearn.metrics.classification_report'], dict]) -> dict:\n",
    "    '''\n",
    "    Extract required metrics from `sklearn.metrics.classification_report`\n",
    "    and transform it into `wandb.Artefact` friendly format\n",
    "\n",
    "    report - `sklearn.metrics.classifcation_report(..., output_dict=True)`; report as dictionary\n",
    "    '''\n",
    "    new_dict = {\n",
    "        'accuracy': None,\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1-score': []\n",
    "    }\n",
    "    new_dict['accuracy'] = report['accuracy']\n",
    "    for k in (['0', '1', 'macro avg']):\n",
    "        for metric in ['precision', 'recall', 'f1-score']:\n",
    "            new_dict[metric].append({f'{k}_{metric}': report[k][metric]})\n",
    "\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_excel('ucy_eko_data.xlsx', sheet_name='smile_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = FeatureExtractor(sales, target_month=3)\n",
    "X_train, X_test, y_train, y_test = fe.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scaling', RobustScaler()),\n",
    "        ('lightgbm', lgb.LGBMClassifier(n_jobs=-1, random_state=1))\n",
    "    ]\n",
    ")\n",
    "config = pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6f5d514a0f4566b70afa6b978bfced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01673183888196945, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/fedorturchenko/Documents/UCY/DSC-571/dsc-571/wandb/run-20230719_143250-fu2cwgss</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/fu2cwgss' target=\"_blank\">robust_scaling_initial_run_2023-07-19_14-32-50</a></strong> to <a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier' target=\"_blank\">https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/fu2cwgss' target=\"_blank\">https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/fu2cwgss</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 29528, number of negative: 25893\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 55421, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532794 -> initscore=0.131366\n",
      "[LightGBM] [Info] Start training from score 0.131366\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921803d2911946f4a80b594bfc4b06bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">robust_scaling_initial_run_2023-07-19_14-32-50</strong> at: <a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/fu2cwgss' target=\"_blank\">https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/fu2cwgss</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230719_143250-fu2cwgss/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with utils.init_wandb_run(\n",
    "    name='robust_scaling_initial_run',\n",
    "    model=lgb.LGBMClassifier,\n",
    "    config=config,\n",
    "    group='default_parameters',\n",
    "    job_type='train'\n",
    ") as run:\n",
    "    pipe.fit(X_train, y_train)\n",
    "    train_preds = pipe.predict(X_train)\n",
    "\n",
    "    train_report = parse_classification_report(\n",
    "        classification_report(y_train, train_preds, output_dict=True)\n",
    "    )\n",
    "\n",
    "    metadata = {\n",
    "        'experiment': {\n",
    "            'name': run.name,\n",
    "        },\n",
    "        'classification_report': train_report,\n",
    "        'config': config\n",
    "    }\n",
    "\n",
    "    artifact = wandb.Artifact(\n",
    "        name='train_classification_report',\n",
    "        type='performance_report',\n",
    "        metadata=metadata\n",
    "    )\n",
    "    run.log_artifact(artifact)\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/fedorturchenko/Documents/UCY/DSC-571/dsc-571/wandb/run-20230719_143302-hsdu2ob4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/hsdu2ob4' target=\"_blank\">robust_scaling_initial_run_2023-07-19_14-33-02</a></strong> to <a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier' target=\"_blank\">https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/hsdu2ob4' target=\"_blank\">https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/hsdu2ob4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bef01e8cd6416e879575e8ab825f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">robust_scaling_initial_run_2023-07-19_14-33-02</strong> at: <a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/hsdu2ob4' target=\"_blank\">https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/hsdu2ob4</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230719_143302-hsdu2ob4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with utils.init_wandb_run(\n",
    "    name='robust_scaling_initial_run',\n",
    "    model=lgb.LGBMClassifier,\n",
    "    config=config,\n",
    "    group='default_parameters',\n",
    "    job_type='test'\n",
    ") as run:\n",
    "    test_preds = pipe.predict(X_test)\n",
    "\n",
    "    test_report = parse_classification_report(\n",
    "        classification_report(y_test, test_preds, output_dict=True)\n",
    "    )\n",
    "\n",
    "    metadata = {\n",
    "        'experiment': {\n",
    "            'name': run.name,\n",
    "        },\n",
    "        'classification_report': test_report,\n",
    "        'config': config\n",
    "    }\n",
    "\n",
    "    artifact = wandb.Artifact(\n",
    "        name='test_classification_report',\n",
    "        type='performance_report',\n",
    "        metadata=metadata\n",
    "    )\n",
    "    run.log_artifact(artifact)\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'lightgbm__max_depth': [10, 50, 100],\n",
    "    'lightgbm__num_leaves': [5, 7, 10],\n",
    "    'lightgbm__n_estimators': [100, 1000, 10000],\n",
    "    'lightgbm__learning_rate': [0.0001, 0.001, 0.1]\n",
    "}\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scaling', RobustScaler()),\n",
    "        ('lightgbm', lgb.LGBMClassifier(n_jobs=-1, random_state=1))\n",
    "    ]\n",
    ")\n",
    "config = pipe.get_params()\n",
    "\n",
    "search = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=10,\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "[CV 1/10; 1/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 1/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 2/10; 1/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 1/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 3/10; 1/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 1/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 4/10; 1/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 1/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 5/10; 1/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 1/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 6/10; 1/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 1/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 7/10; 1/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 1/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 8/10; 1/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 1/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 9/10; 1/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 1/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 10/10; 1/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 1/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 1/10; 2/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 2/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 2/10; 2/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 2/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 3/10; 2/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 2/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 4/10; 2/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 2/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 5/10; 2/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 2/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 6/10; 2/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 2/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 7/10; 2/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 2/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 8/10; 2/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 2/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 9/10; 2/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 2/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 10/10; 2/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 2/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 1/10; 3/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 3/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.2s\n",
      "[CV 2/10; 3/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 3/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.2s\n",
      "[CV 3/10; 3/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 3/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.2s\n",
      "[CV 4/10; 3/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 3/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 5/10; 3/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 3/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 6/10; 3/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 3/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.2s\n",
      "[CV 7/10; 3/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 3/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 8/10; 3/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 3/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 9/10; 3/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 3/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 10/10; 3/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 3/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 1/10; 4/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 4/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.6s\n",
      "[CV 2/10; 4/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 4/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.5s\n",
      "[CV 3/10; 4/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 4/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.6s\n",
      "[CV 4/10; 4/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 4/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.5s\n",
      "[CV 5/10; 4/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 4/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.6s\n",
      "[CV 6/10; 4/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 4/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.5s\n",
      "[CV 7/10; 4/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 4/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.5s\n",
      "[CV 8/10; 4/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 4/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.5s\n",
      "[CV 9/10; 4/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 4/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.5s\n",
      "[CV 10/10; 4/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 4/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.5s\n",
      "[CV 1/10; 5/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 5/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   2.0s\n",
      "[CV 2/10; 5/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 5/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   1.9s\n",
      "[CV 3/10; 5/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 5/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   2.0s\n",
      "[CV 4/10; 5/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 5/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   2.1s\n",
      "[CV 5/10; 5/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 5/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   2.0s\n",
      "[CV 6/10; 5/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 5/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   1.9s\n",
      "[CV 7/10; 5/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 5/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   2.0s\n",
      "[CV 8/10; 5/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 5/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   2.1s\n",
      "[CV 9/10; 5/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 5/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   2.0s\n",
      "[CV 10/10; 5/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 5/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   2.0s\n",
      "[CV 1/10; 6/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 6/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.563 total time=   2.5s\n",
      "[CV 2/10; 6/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 6/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.573 total time=   2.5s\n",
      "[CV 3/10; 6/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 6/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.573 total time=   2.4s\n",
      "[CV 4/10; 6/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 6/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.568 total time=   2.3s\n",
      "[CV 5/10; 6/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 6/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.574 total time=   2.4s\n",
      "[CV 6/10; 6/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 6/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.574 total time=   2.4s\n",
      "[CV 7/10; 6/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 6/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.567 total time=   2.4s\n",
      "[CV 8/10; 6/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 6/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.575 total time=   2.5s\n",
      "[CV 9/10; 6/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 6/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.570 total time=   2.3s\n",
      "[CV 10/10; 6/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 6/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.569 total time=   2.3s\n",
      "[CV 1/10; 7/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 7/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.688 total time=  14.4s\n",
      "[CV 2/10; 7/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 7/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.702 total time=  13.9s\n",
      "[CV 3/10; 7/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 7/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.713 total time=  14.1s\n",
      "[CV 4/10; 7/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 7/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.703 total time=  14.0s\n",
      "[CV 5/10; 7/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 7/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.711 total time=  14.2s\n",
      "[CV 6/10; 7/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 7/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.703 total time=  14.0s\n",
      "[CV 7/10; 7/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 7/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.696 total time=  14.7s\n",
      "[CV 8/10; 7/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 7/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.716 total time=  14.1s\n",
      "[CV 9/10; 7/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 7/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.700 total time=  14.1s\n",
      "[CV 10/10; 7/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 7/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.701 total time=  14.0s\n",
      "[CV 1/10; 8/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 8/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.694 total time=  17.3s\n",
      "[CV 2/10; 8/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 8/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.710 total time=  18.0s\n",
      "[CV 3/10; 8/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 8/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.715 total time=  19.9s\n",
      "[CV 4/10; 8/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 8/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.708 total time=  18.3s\n",
      "[CV 5/10; 8/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 8/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.712 total time=  19.7s\n",
      "[CV 6/10; 8/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 8/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.706 total time=  20.0s\n",
      "[CV 7/10; 8/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 8/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.705 total time=  20.1s\n",
      "[CV 8/10; 8/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 8/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.716 total time=  18.6s\n",
      "[CV 9/10; 8/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 8/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.703 total time=  18.1s\n",
      "[CV 10/10; 8/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 8/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.704 total time=  18.9s\n",
      "[CV 1/10; 9/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 9/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.697 total time=  22.5s\n",
      "[CV 2/10; 9/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 9/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.711 total time=  22.1s\n",
      "[CV 3/10; 9/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 9/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.713 total time=  22.3s\n",
      "[CV 4/10; 9/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 9/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.710 total time=  22.0s\n",
      "[CV 5/10; 9/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 9/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.711 total time=  22.2s\n",
      "[CV 6/10; 9/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 9/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.705 total time=  22.1s\n",
      "[CV 7/10; 9/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 9/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.706 total time=  22.2s\n",
      "[CV 8/10; 9/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 9/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.717 total time=  22.2s\n",
      "[CV 9/10; 9/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 9/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.703 total time=  22.4s\n",
      "[CV 10/10; 9/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 9/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.706 total time=  22.2s\n",
      "[CV 1/10; 10/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 10/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 2/10; 10/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 10/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 3/10; 10/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 10/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 4/10; 10/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 10/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 5/10; 10/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 10/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 6/10; 10/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 10/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 7/10; 10/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001802 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 10/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 8/10; 10/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 10/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 9/10; 10/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 10/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 10/10; 10/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 10/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 1/10; 11/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 11/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 2/10; 11/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 11/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 3/10; 11/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 11/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 4/10; 11/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 11/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 5/10; 11/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 11/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 6/10; 11/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 11/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 7/10; 11/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 11/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 8/10; 11/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 11/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 9/10; 11/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 11/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 10/10; 11/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 11/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 1/10; 12/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 12/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 2/10; 12/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 12/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 3/10; 12/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 12/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 4/10; 12/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 12/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 5/10; 12/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 12/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 6/10; 12/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 12/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 7/10; 12/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 12/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 8/10; 12/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 12/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 9/10; 12/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 12/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 10/10; 12/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 12/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 1/10; 13/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 13/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.5s\n",
      "[CV 2/10; 13/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 13/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.5s\n",
      "[CV 3/10; 13/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 13/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.5s\n",
      "[CV 4/10; 13/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 13/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.5s\n",
      "[CV 5/10; 13/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 13/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.5s\n",
      "[CV 6/10; 13/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 13/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.5s\n",
      "[CV 7/10; 13/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 13/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.5s\n",
      "[CV 8/10; 13/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 13/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.6s\n",
      "[CV 9/10; 13/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 13/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.5s\n",
      "[CV 10/10; 13/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 13/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.5s\n",
      "[CV 1/10; 14/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 14/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   1.9s\n",
      "[CV 2/10; 14/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 14/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   1.8s\n",
      "[CV 3/10; 14/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 14/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   1.8s\n",
      "[CV 4/10; 14/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 14/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   1.8s\n",
      "[CV 5/10; 14/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 14/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   1.8s\n",
      "[CV 6/10; 14/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 14/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   1.9s\n",
      "[CV 7/10; 14/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 14/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   1.8s\n",
      "[CV 8/10; 14/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 14/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   1.9s\n",
      "[CV 9/10; 14/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 14/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   1.8s\n",
      "[CV 10/10; 14/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 14/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   1.8s\n",
      "[CV 1/10; 15/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 15/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.563 total time=   2.3s\n",
      "[CV 2/10; 15/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 15/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.573 total time=   2.3s\n",
      "[CV 3/10; 15/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 15/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.573 total time=   2.5s\n",
      "[CV 4/10; 15/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 15/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.568 total time=   2.5s\n",
      "[CV 5/10; 15/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 15/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.574 total time=   2.4s\n",
      "[CV 6/10; 15/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 15/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.574 total time=   2.4s\n",
      "[CV 7/10; 15/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 15/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.567 total time=   2.5s\n",
      "[CV 8/10; 15/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 15/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.575 total time=   2.4s\n",
      "[CV 9/10; 15/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 15/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.570 total time=   2.4s\n",
      "[CV 10/10; 15/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 15/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.569 total time=   2.4s\n",
      "[CV 1/10; 16/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 16/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.688 total time=  14.1s\n",
      "[CV 2/10; 16/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 16/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.702 total time=  14.0s\n",
      "[CV 3/10; 16/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 16/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.713 total time=  14.3s\n",
      "[CV 4/10; 16/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 16/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.703 total time=  14.0s\n",
      "[CV 5/10; 16/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 16/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.711 total time=  14.2s\n",
      "[CV 6/10; 16/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 16/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.703 total time=  14.1s\n",
      "[CV 7/10; 16/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 16/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.696 total time=  14.1s\n",
      "[CV 8/10; 16/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 16/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.716 total time=  14.1s\n",
      "[CV 9/10; 16/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 16/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.700 total time=  14.1s\n",
      "[CV 10/10; 16/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 16/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.701 total time=  14.0s\n",
      "[CV 1/10; 17/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 17/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.694 total time=  17.5s\n",
      "[CV 2/10; 17/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 17/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.710 total time=  18.5s\n",
      "[CV 3/10; 17/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 17/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.715 total time=  17.6s\n",
      "[CV 4/10; 17/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 17/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.708 total time=  17.5s\n",
      "[CV 5/10; 17/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 17/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.712 total time=  17.5s\n",
      "[CV 6/10; 17/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 17/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.706 total time=  17.5s\n",
      "[CV 7/10; 17/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 17/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.705 total time=  17.4s\n",
      "[CV 8/10; 17/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 17/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.716 total time=  17.5s\n",
      "[CV 9/10; 17/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 17/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.703 total time=  17.7s\n",
      "[CV 10/10; 17/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 17/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.704 total time=  17.8s\n",
      "[CV 1/10; 18/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 18/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.697 total time=  22.3s\n",
      "[CV 2/10; 18/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 18/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.711 total time=  25.4s\n",
      "[CV 3/10; 18/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 18/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.713 total time=  23.2s\n",
      "[CV 4/10; 18/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 18/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.710 total time=  23.3s\n",
      "[CV 5/10; 18/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 18/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.711 total time=  23.7s\n",
      "[CV 6/10; 18/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 18/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.705 total time=  23.4s\n",
      "[CV 7/10; 18/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 18/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.706 total time=  23.8s\n",
      "[CV 8/10; 18/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 18/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.717 total time=  23.6s\n",
      "[CV 9/10; 18/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 18/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.703 total time=  24.0s\n",
      "[CV 10/10; 18/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 18/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.706 total time=  23.8s\n",
      "[CV 1/10; 19/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 19/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.3s\n",
      "[CV 2/10; 19/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 19/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 3/10; 19/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 19/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 4/10; 19/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 19/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 5/10; 19/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 19/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 6/10; 19/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 19/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 7/10; 19/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 19/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 8/10; 19/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 19/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 9/10; 19/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 19/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 10/10; 19/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 19/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 1/10; 20/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 20/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 2/10; 20/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 20/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 3/10; 20/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 20/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 4/10; 20/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 20/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 5/10; 20/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 20/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 6/10; 20/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 20/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 7/10; 20/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 20/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 8/10; 20/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001799 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 20/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 9/10; 20/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 20/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 10/10; 20/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 20/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 1/10; 21/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 21/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 2/10; 21/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 21/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 3/10; 21/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 21/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 4/10; 21/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 21/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 5/10; 21/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 21/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 6/10; 21/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 21/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 7/10; 21/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 21/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 8/10; 21/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 21/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 9/10; 21/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 21/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 10/10; 21/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 21/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.533 total time=   0.3s\n",
      "[CV 1/10; 22/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 22/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.6s\n",
      "[CV 2/10; 22/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 22/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.6s\n",
      "[CV 3/10; 22/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 22/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.6s\n",
      "[CV 4/10; 22/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 22/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.6s\n",
      "[CV 5/10; 22/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 22/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.8s\n",
      "[CV 6/10; 22/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 22/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.6s\n",
      "[CV 7/10; 22/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 22/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.6s\n",
      "[CV 8/10; 22/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 22/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.6s\n",
      "[CV 9/10; 22/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 22/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.6s\n",
      "[CV 10/10; 22/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 22/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.533 total time=   1.7s\n",
      "[CV 1/10; 23/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 23/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   2.0s\n",
      "[CV 2/10; 23/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 23/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   2.0s\n",
      "[CV 3/10; 23/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 23/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   2.1s\n",
      "[CV 4/10; 23/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 23/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   2.1s\n",
      "[CV 5/10; 23/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 23/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   1.9s\n",
      "[CV 6/10; 23/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 23/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   2.0s\n",
      "[CV 7/10; 23/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 23/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   1.9s\n",
      "[CV 8/10; 23/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 23/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   2.0s\n",
      "[CV 9/10; 23/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 23/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   2.0s\n",
      "[CV 10/10; 23/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 23/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.533 total time=   2.0s\n",
      "[CV 1/10; 24/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 24/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.563 total time=   2.5s\n",
      "[CV 2/10; 24/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 24/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.573 total time=   2.5s\n",
      "[CV 3/10; 24/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 24/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.573 total time=   2.5s\n",
      "[CV 4/10; 24/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 24/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.568 total time=   2.4s\n",
      "[CV 5/10; 24/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 24/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.574 total time=   2.5s\n",
      "[CV 6/10; 24/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 24/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.574 total time=   2.6s\n",
      "[CV 7/10; 24/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 24/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.567 total time=   2.6s\n",
      "[CV 8/10; 24/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 24/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.575 total time=   2.5s\n",
      "[CV 9/10; 24/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 24/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.570 total time=   2.7s\n",
      "[CV 10/10; 24/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 24/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.569 total time=   2.9s\n",
      "[CV 1/10; 25/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 25/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.688 total time=  14.9s\n",
      "[CV 2/10; 25/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 25/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.702 total time=  14.9s\n",
      "[CV 3/10; 25/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 25/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.713 total time=  15.0s\n",
      "[CV 4/10; 25/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 25/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.703 total time=  16.8s\n",
      "[CV 5/10; 25/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 25/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.711 total time=  18.1s\n",
      "[CV 6/10; 25/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 25/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.703 total time=  15.2s\n",
      "[CV 7/10; 25/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 25/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.696 total time=  15.1s\n",
      "[CV 8/10; 25/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 25/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.716 total time=  14.9s\n",
      "[CV 9/10; 25/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 25/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.700 total time=  14.9s\n",
      "[CV 10/10; 25/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 25/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.701 total time=  15.4s\n",
      "[CV 1/10; 26/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 26/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.694 total time=  18.4s\n",
      "[CV 2/10; 26/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 26/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.710 total time=  18.4s\n",
      "[CV 3/10; 26/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 26/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.715 total time=  18.4s\n",
      "[CV 4/10; 26/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 26/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.708 total time=  18.4s\n",
      "[CV 5/10; 26/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 26/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.712 total time=  18.6s\n",
      "[CV 6/10; 26/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 26/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.706 total time=  18.4s\n",
      "[CV 7/10; 26/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 26/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.705 total time=  18.4s\n",
      "[CV 8/10; 26/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 26/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.716 total time=  20.0s\n",
      "[CV 9/10; 26/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 26/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.703 total time=  20.1s\n",
      "[CV 10/10; 26/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 26/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.704 total time=  18.4s\n",
      "[CV 1/10; 27/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 27/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.697 total time=  23.6s\n",
      "[CV 2/10; 27/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 27/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.711 total time=  23.6s\n",
      "[CV 3/10; 27/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 27/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.713 total time=  24.4s\n",
      "[CV 4/10; 27/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 27/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.710 total time=  24.1s\n",
      "[CV 5/10; 27/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 27/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.711 total time=  24.1s\n",
      "[CV 6/10; 27/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 27/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.705 total time=  24.0s\n",
      "[CV 7/10; 27/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 27/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.706 total time=  23.9s\n",
      "[CV 8/10; 27/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 27/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.717 total time=  24.0s\n",
      "[CV 9/10; 27/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 27/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.703 total time=  23.9s\n",
      "[CV 10/10; 27/81] START lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 27/81] END lightgbm__learning_rate=0.0001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.706 total time=  24.0s\n",
      "[CV 1/10; 28/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 28/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.3s\n",
      "[CV 2/10; 28/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 28/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 3/10; 28/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 28/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 4/10; 28/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 28/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 5/10; 28/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 28/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 6/10; 28/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 28/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.3s\n",
      "[CV 7/10; 28/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 28/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 8/10; 28/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 28/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 9/10; 28/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 28/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 10/10; 28/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 28/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 1/10; 29/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 29/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 2/10; 29/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 29/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 3/10; 29/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 29/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 4/10; 29/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 29/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 5/10; 29/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 29/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 6/10; 29/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 29/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 7/10; 29/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 29/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 8/10; 29/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 29/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 9/10; 29/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 29/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 10/10; 29/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 29/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 1/10; 30/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 30/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.563 total time=   0.3s\n",
      "[CV 2/10; 30/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 30/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.573 total time=   0.3s\n",
      "[CV 3/10; 30/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 30/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.573 total time=   0.3s\n",
      "[CV 4/10; 30/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 30/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.568 total time=   0.3s\n",
      "[CV 5/10; 30/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 30/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.574 total time=   0.4s\n",
      "[CV 6/10; 30/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 30/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.574 total time=   0.3s\n",
      "[CV 7/10; 30/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 30/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.567 total time=   0.3s\n",
      "[CV 8/10; 30/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 30/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.575 total time=   0.3s\n",
      "[CV 9/10; 30/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 30/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.570 total time=   0.3s\n",
      "[CV 10/10; 30/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 30/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.569 total time=   0.3s\n",
      "[CV 1/10; 31/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 31/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.688 total time=   1.5s\n",
      "[CV 2/10; 31/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 31/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.702 total time=   1.6s\n",
      "[CV 3/10; 31/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 31/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.707 total time=   1.5s\n",
      "[CV 4/10; 31/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 31/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.703 total time=   1.5s\n",
      "[CV 5/10; 31/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 31/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.711 total time=   1.5s\n",
      "[CV 6/10; 31/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 31/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.703 total time=   1.6s\n",
      "[CV 7/10; 31/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 31/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.696 total time=   1.6s\n",
      "[CV 8/10; 31/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 31/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.716 total time=   1.5s\n",
      "[CV 9/10; 31/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 31/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.700 total time=   1.6s\n",
      "[CV 10/10; 31/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 31/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.701 total time=   1.5s\n",
      "[CV 1/10; 32/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 32/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.694 total time=   1.9s\n",
      "[CV 2/10; 32/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 32/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.710 total time=   1.9s\n",
      "[CV 3/10; 32/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 32/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.715 total time=   1.9s\n",
      "[CV 4/10; 32/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 32/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.708 total time=   1.9s\n",
      "[CV 5/10; 32/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 32/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.712 total time=   1.9s\n",
      "[CV 6/10; 32/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 32/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.706 total time=   1.9s\n",
      "[CV 7/10; 32/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 32/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.705 total time=   2.0s\n",
      "[CV 8/10; 32/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 32/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.716 total time=   2.0s\n",
      "[CV 9/10; 32/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 32/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.703 total time=   1.9s\n",
      "[CV 10/10; 32/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 32/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.704 total time=   2.0s\n",
      "[CV 1/10; 33/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 33/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.697 total time=   2.4s\n",
      "[CV 2/10; 33/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 33/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.711 total time=   2.3s\n",
      "[CV 3/10; 33/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 33/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.713 total time=   2.4s\n",
      "[CV 4/10; 33/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 33/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.710 total time=   2.6s\n",
      "[CV 5/10; 33/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 33/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.711 total time=   2.4s\n",
      "[CV 6/10; 33/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 33/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.705 total time=   2.4s\n",
      "[CV 7/10; 33/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 33/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.705 total time=   2.4s\n",
      "[CV 8/10; 33/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 33/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.717 total time=   2.4s\n",
      "[CV 9/10; 33/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 33/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.703 total time=   2.3s\n",
      "[CV 10/10; 33/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 33/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.706 total time=   2.5s\n",
      "[CV 1/10; 34/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 34/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.702 total time=  13.8s\n",
      "[CV 2/10; 34/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 34/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.715 total time=  13.9s\n",
      "[CV 3/10; 34/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 34/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.714 total time=  13.9s\n",
      "[CV 4/10; 34/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 34/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.712 total time=  14.7s\n",
      "[CV 5/10; 34/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 34/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.714 total time=  16.6s\n",
      "[CV 6/10; 34/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 34/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.709 total time=  15.6s\n",
      "[CV 7/10; 34/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 34/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.706 total time=  14.6s\n",
      "[CV 8/10; 34/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 34/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.720 total time=  14.7s\n",
      "[CV 9/10; 34/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 34/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.709 total time=  14.0s\n",
      "[CV 10/10; 34/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 34/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.706 total time=  13.6s\n",
      "[CV 1/10; 35/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 35/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.702 total time=  16.3s\n",
      "[CV 2/10; 35/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 35/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.716 total time=  16.4s\n",
      "[CV 3/10; 35/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 35/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.715 total time=  15.8s\n",
      "[CV 4/10; 35/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 35/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.713 total time=  15.6s\n",
      "[CV 5/10; 35/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 35/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.714 total time=  15.3s\n",
      "[CV 6/10; 35/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 35/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.711 total time=  15.1s\n",
      "[CV 7/10; 35/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 35/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.705 total time=  15.3s\n",
      "[CV 8/10; 35/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 35/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.719 total time=  15.6s\n",
      "[CV 9/10; 35/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 35/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.710 total time=  15.7s\n",
      "[CV 10/10; 35/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 35/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.706 total time=  15.8s\n",
      "[CV 1/10; 36/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 36/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.701 total time=  19.4s\n",
      "[CV 2/10; 36/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 36/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.717 total time=  19.6s\n",
      "[CV 3/10; 36/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 36/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.715 total time=  19.8s\n",
      "[CV 4/10; 36/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 36/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.712 total time=  20.6s\n",
      "[CV 5/10; 36/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 36/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.715 total time=  21.3s\n",
      "[CV 6/10; 36/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 36/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.711 total time=  19.9s\n",
      "[CV 7/10; 36/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 36/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.705 total time=  19.7s\n",
      "[CV 8/10; 36/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001954 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 36/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.720 total time=  19.9s\n",
      "[CV 9/10; 36/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 36/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.709 total time=  20.2s\n",
      "[CV 10/10; 36/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 36/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.705 total time=  20.2s\n",
      "[CV 1/10; 37/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 37/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 2/10; 37/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 37/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 3/10; 37/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 37/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 4/10; 37/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 37/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 5/10; 37/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 37/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.3s\n",
      "[CV 6/10; 37/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 37/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 7/10; 37/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 37/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 8/10; 37/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 37/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 9/10; 37/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 37/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 10/10; 37/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 37/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 1/10; 38/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 38/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 2/10; 38/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 38/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 3/10; 38/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 38/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 4/10; 38/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 38/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 5/10; 38/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 38/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 6/10; 38/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 38/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 7/10; 38/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 38/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 8/10; 38/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 38/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 9/10; 38/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 38/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 10/10; 38/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 38/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.2s\n",
      "[CV 1/10; 39/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 39/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.563 total time=   0.3s\n",
      "[CV 2/10; 39/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 39/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.573 total time=   0.3s\n",
      "[CV 3/10; 39/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 39/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.573 total time=   0.3s\n",
      "[CV 4/10; 39/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 39/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.568 total time=   0.3s\n",
      "[CV 5/10; 39/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 39/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.574 total time=   0.4s\n",
      "[CV 6/10; 39/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 39/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.574 total time=   0.3s\n",
      "[CV 7/10; 39/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 39/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.567 total time=   0.3s\n",
      "[CV 8/10; 39/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 39/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.575 total time=   0.3s\n",
      "[CV 9/10; 39/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 39/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.570 total time=   0.3s\n",
      "[CV 10/10; 39/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 39/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.569 total time=   0.3s\n",
      "[CV 1/10; 40/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 40/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.688 total time=   1.4s\n",
      "[CV 2/10; 40/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 40/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.702 total time=   1.5s\n",
      "[CV 3/10; 40/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 40/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.707 total time=   1.5s\n",
      "[CV 4/10; 40/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 40/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.703 total time=   1.5s\n",
      "[CV 5/10; 40/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 40/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.711 total time=   1.5s\n",
      "[CV 6/10; 40/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 40/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.703 total time=   1.5s\n",
      "[CV 7/10; 40/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 40/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.696 total time=   1.5s\n",
      "[CV 8/10; 40/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 40/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.716 total time=   1.5s\n",
      "[CV 9/10; 40/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 40/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.700 total time=   1.6s\n",
      "[CV 10/10; 40/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 40/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.701 total time=   1.5s\n",
      "[CV 1/10; 41/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 41/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.694 total time=   1.8s\n",
      "[CV 2/10; 41/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 41/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.710 total time=   1.8s\n",
      "[CV 3/10; 41/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 41/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.715 total time=   1.8s\n",
      "[CV 4/10; 41/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 41/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.708 total time=   1.8s\n",
      "[CV 5/10; 41/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 41/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.712 total time=   1.8s\n",
      "[CV 6/10; 41/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 41/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.706 total time=   1.8s\n",
      "[CV 7/10; 41/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 41/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.705 total time=   1.8s\n",
      "[CV 8/10; 41/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 41/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.716 total time=   2.0s\n",
      "[CV 9/10; 41/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 41/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.703 total time=   1.8s\n",
      "[CV 10/10; 41/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 41/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.704 total time=   1.8s\n",
      "[CV 1/10; 42/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 42/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.697 total time=   2.3s\n",
      "[CV 2/10; 42/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 42/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.711 total time=   2.3s\n",
      "[CV 3/10; 42/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 42/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.713 total time=   2.3s\n",
      "[CV 4/10; 42/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 42/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.710 total time=   2.3s\n",
      "[CV 5/10; 42/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 42/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.711 total time=   2.4s\n",
      "[CV 6/10; 42/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 42/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.705 total time=   2.3s\n",
      "[CV 7/10; 42/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 42/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.705 total time=   2.3s\n",
      "[CV 8/10; 42/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 42/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.717 total time=   2.3s\n",
      "[CV 9/10; 42/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 42/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.703 total time=   2.3s\n",
      "[CV 10/10; 42/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 42/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.706 total time=   2.3s\n",
      "[CV 1/10; 43/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 43/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.702 total time=  13.5s\n",
      "[CV 2/10; 43/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 43/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.715 total time=  13.3s\n",
      "[CV 3/10; 43/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 43/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.714 total time=  13.3s\n",
      "[CV 4/10; 43/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 43/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.712 total time=  14.0s\n",
      "[CV 5/10; 43/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 43/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.714 total time=  14.0s\n",
      "[CV 6/10; 43/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 43/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.709 total time=  14.4s\n",
      "[CV 7/10; 43/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 43/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.706 total time=  15.1s\n",
      "[CV 8/10; 43/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 43/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.720 total time=  14.3s\n",
      "[CV 9/10; 43/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 43/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.709 total time=  14.6s\n",
      "[CV 10/10; 43/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 43/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.706 total time=  15.2s\n",
      "[CV 1/10; 44/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 44/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.702 total time=  17.0s\n",
      "[CV 2/10; 44/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 44/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.716 total time=  17.2s\n",
      "[CV 3/10; 44/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 44/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.715 total time=  16.7s\n",
      "[CV 4/10; 44/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 44/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.713 total time=  17.6s\n",
      "[CV 5/10; 44/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 44/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.714 total time=  16.7s\n",
      "[CV 6/10; 44/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 44/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.711 total time=  17.2s\n",
      "[CV 7/10; 44/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 44/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.705 total time=  17.0s\n",
      "[CV 8/10; 44/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 44/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.719 total time=  16.7s\n",
      "[CV 9/10; 44/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 44/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.710 total time=  17.0s\n",
      "[CV 10/10; 44/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 44/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.706 total time=  18.9s\n",
      "[CV 1/10; 45/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 45/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.701 total time=  23.4s\n",
      "[CV 2/10; 45/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 45/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.717 total time=  21.3s\n",
      "[CV 3/10; 45/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 45/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.715 total time=  23.0s\n",
      "[CV 4/10; 45/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 45/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.712 total time=  23.0s\n",
      "[CV 5/10; 45/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 45/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.715 total time=  21.7s\n",
      "[CV 6/10; 45/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 45/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.711 total time=  21.7s\n",
      "[CV 7/10; 45/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 45/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.705 total time=  21.8s\n",
      "[CV 8/10; 45/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 45/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.720 total time=  22.0s\n",
      "[CV 9/10; 45/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 45/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.709 total time=  21.8s\n",
      "[CV 10/10; 45/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 45/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.705 total time=  21.9s\n",
      "[CV 1/10; 46/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 46/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.3s\n",
      "[CV 2/10; 46/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 46/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 3/10; 46/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 46/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 4/10; 46/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 46/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.3s\n",
      "[CV 5/10; 46/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 46/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 6/10; 46/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 46/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 7/10; 46/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 46/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 8/10; 46/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 46/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 9/10; 46/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 46/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.3s\n",
      "[CV 10/10; 46/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 46/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.533 total time=   0.2s\n",
      "[CV 1/10; 47/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 47/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 2/10; 47/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 47/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 3/10; 47/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 47/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 4/10; 47/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 47/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 5/10; 47/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 47/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 6/10; 47/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 47/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 7/10; 47/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 47/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 8/10; 47/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 47/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 9/10; 47/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 47/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 10/10; 47/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 47/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.533 total time=   0.3s\n",
      "[CV 1/10; 48/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 48/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.563 total time=   0.4s\n",
      "[CV 2/10; 48/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 48/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.573 total time=   0.3s\n",
      "[CV 3/10; 48/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 48/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.573 total time=   0.4s\n",
      "[CV 4/10; 48/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 48/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.568 total time=   0.4s\n",
      "[CV 5/10; 48/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 48/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.574 total time=   0.3s\n",
      "[CV 6/10; 48/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 48/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.574 total time=   0.4s\n",
      "[CV 7/10; 48/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 48/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.567 total time=   0.3s\n",
      "[CV 8/10; 48/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 48/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.575 total time=   0.3s\n",
      "[CV 9/10; 48/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 48/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.570 total time=   0.3s\n",
      "[CV 10/10; 48/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 48/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.569 total time=   0.3s\n",
      "[CV 1/10; 49/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 49/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.688 total time=   1.6s\n",
      "[CV 2/10; 49/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 49/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.702 total time=   1.8s\n",
      "[CV 3/10; 49/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 49/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.707 total time=   1.9s\n",
      "[CV 4/10; 49/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 49/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.703 total time=   1.7s\n",
      "[CV 5/10; 49/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 49/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.711 total time=   1.7s\n",
      "[CV 6/10; 49/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 49/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.703 total time=   1.7s\n",
      "[CV 7/10; 49/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 49/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.696 total time=   1.7s\n",
      "[CV 8/10; 49/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 49/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.716 total time=   1.8s\n",
      "[CV 9/10; 49/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 49/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.700 total time=   1.7s\n",
      "[CV 10/10; 49/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 49/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.701 total time=   1.6s\n",
      "[CV 1/10; 50/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 50/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.694 total time=   2.0s\n",
      "[CV 2/10; 50/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 50/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.710 total time=   2.0s\n",
      "[CV 3/10; 50/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 50/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.715 total time=   2.0s\n",
      "[CV 4/10; 50/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 50/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.708 total time=   2.0s\n",
      "[CV 5/10; 50/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 50/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.712 total time=   2.4s\n",
      "[CV 6/10; 50/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 50/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.706 total time=   2.2s\n",
      "[CV 7/10; 50/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 50/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.705 total time=   2.0s\n",
      "[CV 8/10; 50/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 50/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.716 total time=   2.1s\n",
      "[CV 9/10; 50/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 50/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.703 total time=   2.0s\n",
      "[CV 10/10; 50/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 50/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.704 total time=   1.9s\n",
      "[CV 1/10; 51/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 51/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.697 total time=   2.7s\n",
      "[CV 2/10; 51/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 51/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.711 total time=   2.6s\n",
      "[CV 3/10; 51/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 51/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.713 total time=   2.5s\n",
      "[CV 4/10; 51/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 51/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.710 total time=   2.6s\n",
      "[CV 5/10; 51/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 51/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.711 total time=   2.6s\n",
      "[CV 6/10; 51/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 51/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.705 total time=   2.5s\n",
      "[CV 7/10; 51/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 51/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.705 total time=   2.6s\n",
      "[CV 8/10; 51/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 51/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.717 total time=   2.7s\n",
      "[CV 9/10; 51/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 51/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.703 total time=   2.6s\n",
      "[CV 10/10; 51/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 51/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.706 total time=   2.5s\n",
      "[CV 1/10; 52/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 52/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.702 total time=  16.1s\n",
      "[CV 2/10; 52/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 52/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.715 total time=  14.4s\n",
      "[CV 3/10; 52/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 52/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.714 total time=  14.4s\n",
      "[CV 4/10; 52/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 52/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.712 total time=  14.2s\n",
      "[CV 5/10; 52/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 52/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.714 total time=  14.7s\n",
      "[CV 6/10; 52/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 52/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.709 total time=  15.3s\n",
      "[CV 7/10; 52/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 52/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.706 total time=  14.6s\n",
      "[CV 8/10; 52/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 52/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.720 total time=  14.4s\n",
      "[CV 9/10; 52/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 52/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.709 total time=  15.4s\n",
      "[CV 10/10; 52/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 52/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.706 total time=  17.0s\n",
      "[CV 1/10; 53/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 53/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.702 total time=  19.7s\n",
      "[CV 2/10; 53/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 53/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.716 total time=  18.0s\n",
      "[CV 3/10; 53/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 53/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.715 total time=  18.0s\n",
      "[CV 4/10; 53/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 53/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.713 total time=  17.9s\n",
      "[CV 5/10; 53/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 53/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.714 total time=  17.4s\n",
      "[CV 6/10; 53/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 53/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.711 total time=  17.8s\n",
      "[CV 7/10; 53/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 53/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.705 total time=  17.2s\n",
      "[CV 8/10; 53/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 53/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.719 total time=  17.1s\n",
      "[CV 9/10; 53/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 53/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.710 total time=  17.7s\n",
      "[CV 10/10; 53/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 53/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.706 total time=  18.4s\n",
      "[CV 1/10; 54/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 54/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.701 total time=  22.6s\n",
      "[CV 2/10; 54/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 54/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.717 total time=  22.3s\n",
      "[CV 3/10; 54/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 54/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.715 total time=  22.0s\n",
      "[CV 4/10; 54/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 54/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.712 total time=  22.0s\n",
      "[CV 5/10; 54/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 54/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.715 total time=  21.5s\n",
      "[CV 6/10; 54/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 54/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.711 total time=  22.9s\n",
      "[CV 7/10; 54/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 54/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.705 total time=  23.4s\n",
      "[CV 8/10; 54/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 54/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.720 total time=  23.0s\n",
      "[CV 9/10; 54/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 54/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.709 total time=  21.8s\n",
      "[CV 10/10; 54/81] START lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 54/81] END lightgbm__learning_rate=0.001, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.705 total time=  22.1s\n",
      "[CV 1/10; 55/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 55/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.703 total time=   0.3s\n",
      "[CV 2/10; 55/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 55/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.715 total time=   0.2s\n",
      "[CV 3/10; 55/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 55/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.714 total time=   0.3s\n",
      "[CV 4/10; 55/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 55/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.710 total time=   0.3s\n",
      "[CV 5/10; 55/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 55/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.714 total time=   0.3s\n",
      "[CV 6/10; 55/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 55/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.709 total time=   0.3s\n",
      "[CV 7/10; 55/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 55/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.705 total time=   0.3s\n",
      "[CV 8/10; 55/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 55/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.720 total time=   0.3s\n",
      "[CV 9/10; 55/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 55/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.710 total time=   0.3s\n",
      "[CV 10/10; 55/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 55/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.706 total time=   0.3s\n",
      "[CV 1/10; 56/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 56/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.703 total time=   0.4s\n",
      "[CV 2/10; 56/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 56/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.715 total time=   0.3s\n",
      "[CV 3/10; 56/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 56/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.714 total time=   0.3s\n",
      "[CV 4/10; 56/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 56/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.714 total time=   0.4s\n",
      "[CV 5/10; 56/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 56/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.714 total time=   0.3s\n",
      "[CV 6/10; 56/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 56/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.710 total time=   0.4s\n",
      "[CV 7/10; 56/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 56/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.704 total time=   0.3s\n",
      "[CV 8/10; 56/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 56/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.722 total time=   0.4s\n",
      "[CV 9/10; 56/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 56/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.709 total time=   0.3s\n",
      "[CV 10/10; 56/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 56/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.707 total time=   0.3s\n",
      "[CV 1/10; 57/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 57/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.701 total time=   0.4s\n",
      "[CV 2/10; 57/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 57/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.716 total time=   0.4s\n",
      "[CV 3/10; 57/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 57/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.714 total time=   0.4s\n",
      "[CV 4/10; 57/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003024 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 57/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.711 total time=   0.4s\n",
      "[CV 5/10; 57/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 57/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.713 total time=   0.4s\n",
      "[CV 6/10; 57/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 57/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.709 total time=   0.4s\n",
      "[CV 7/10; 57/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 57/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.705 total time=   0.4s\n",
      "[CV 8/10; 57/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 57/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.720 total time=   0.4s\n",
      "[CV 9/10; 57/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 57/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.709 total time=   0.4s\n",
      "[CV 10/10; 57/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 57/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.702 total time=   0.5s\n",
      "[CV 1/10; 58/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 58/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.703 total time=   2.5s\n",
      "[CV 2/10; 58/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 58/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.715 total time=   2.0s\n",
      "[CV 3/10; 58/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 58/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.715 total time=   2.1s\n",
      "[CV 4/10; 58/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 58/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.711 total time=   1.7s\n",
      "[CV 5/10; 58/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 58/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.713 total time=   1.6s\n",
      "[CV 6/10; 58/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 58/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.709 total time=   1.5s\n",
      "[CV 7/10; 58/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 58/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.704 total time=   1.5s\n",
      "[CV 8/10; 58/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 58/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.720 total time=   1.8s\n",
      "[CV 9/10; 58/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 58/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.708 total time=   2.0s\n",
      "[CV 10/10; 58/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 58/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.703 total time=   1.6s\n",
      "[CV 1/10; 59/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 59/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.702 total time=   1.8s\n",
      "[CV 2/10; 59/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 59/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.715 total time=   1.9s\n",
      "[CV 3/10; 59/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 59/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.713 total time=   1.7s\n",
      "[CV 4/10; 59/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 59/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.708 total time=   1.7s\n",
      "[CV 5/10; 59/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 59/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.708 total time=   1.7s\n",
      "[CV 6/10; 59/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 59/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.709 total time=   1.7s\n",
      "[CV 7/10; 59/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 59/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.702 total time=   1.9s\n",
      "[CV 8/10; 59/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 59/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.716 total time=   1.7s\n",
      "[CV 9/10; 59/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 59/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.705 total time=   1.7s\n",
      "[CV 10/10; 59/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 59/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.705 total time=   1.8s\n",
      "[CV 1/10; 60/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 60/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.699 total time=   2.0s\n",
      "[CV 2/10; 60/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 60/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.716 total time=   2.3s\n",
      "[CV 3/10; 60/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 60/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.711 total time=   2.1s\n",
      "[CV 4/10; 60/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 60/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.709 total time=   2.2s\n",
      "[CV 5/10; 60/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 60/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.708 total time=   2.4s\n",
      "[CV 6/10; 60/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 60/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.706 total time=   2.1s\n",
      "[CV 7/10; 60/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 60/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.704 total time=   2.3s\n",
      "[CV 8/10; 60/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 60/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.715 total time=   2.2s\n",
      "[CV 9/10; 60/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 60/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.708 total time=   2.2s\n",
      "[CV 10/10; 60/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 60/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.701 total time=   2.1s\n",
      "[CV 1/10; 61/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 61/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.692 total time=  12.9s\n",
      "[CV 2/10; 61/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 61/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.701 total time=  12.5s\n",
      "[CV 3/10; 61/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 61/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.701 total time=  12.7s\n",
      "[CV 4/10; 61/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 61/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.700 total time=  12.6s\n",
      "[CV 5/10; 61/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 61/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.699 total time=  13.4s\n",
      "[CV 6/10; 61/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 61/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.698 total time=  14.1s\n",
      "[CV 7/10; 61/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 61/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.696 total time=  12.5s\n",
      "[CV 8/10; 61/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 61/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.707 total time=  13.1s\n",
      "[CV 9/10; 61/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 61/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.701 total time=  12.6s\n",
      "[CV 10/10; 61/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 61/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.691 total time=  12.6s\n",
      "[CV 1/10; 62/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 62/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.688 total time=  14.7s\n",
      "[CV 2/10; 62/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 62/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.696 total time=  14.8s\n",
      "[CV 3/10; 62/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 62/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.692 total time=  14.5s\n",
      "[CV 4/10; 62/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 62/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.689 total time=  14.5s\n",
      "[CV 5/10; 62/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 62/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.693 total time=  14.3s\n",
      "[CV 6/10; 62/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 62/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.691 total time=  14.3s\n",
      "[CV 7/10; 62/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 62/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.692 total time=  14.0s\n",
      "[CV 8/10; 62/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 62/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.694 total time=  14.5s\n",
      "[CV 9/10; 62/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 62/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.693 total time=  14.7s\n",
      "[CV 10/10; 62/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 62/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.683 total time=  14.6s\n",
      "[CV 1/10; 63/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 63/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.682 total time=  17.0s\n",
      "[CV 2/10; 63/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 63/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.687 total time=  16.8s\n",
      "[CV 3/10; 63/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 63/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.685 total time=  16.8s\n",
      "[CV 4/10; 63/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 63/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.688 total time=  16.8s\n",
      "[CV 5/10; 63/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 63/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.692 total time=  16.7s\n",
      "[CV 6/10; 63/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 63/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.684 total time=  16.9s\n",
      "[CV 7/10; 63/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 63/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.687 total time=  17.0s\n",
      "[CV 8/10; 63/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 63/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.684 total time=  17.1s\n",
      "[CV 9/10; 63/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 63/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.688 total time=  18.3s\n",
      "[CV 10/10; 63/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 63/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=10, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.683 total time=  17.3s\n",
      "[CV 1/10; 64/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 64/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.703 total time=   0.2s\n",
      "[CV 2/10; 64/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 64/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.715 total time=   0.2s\n",
      "[CV 3/10; 64/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 64/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.714 total time=   0.3s\n",
      "[CV 4/10; 64/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 64/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.710 total time=   0.2s\n",
      "[CV 5/10; 64/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 64/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.714 total time=   0.2s\n",
      "[CV 6/10; 64/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 64/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.709 total time=   0.3s\n",
      "[CV 7/10; 64/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 64/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.705 total time=   0.2s\n",
      "[CV 8/10; 64/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 64/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.720 total time=   0.3s\n",
      "[CV 9/10; 64/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 64/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.710 total time=   0.3s\n",
      "[CV 10/10; 64/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 64/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.706 total time=   0.2s\n",
      "[CV 1/10; 65/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 65/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.703 total time=   0.3s\n",
      "[CV 2/10; 65/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 65/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.715 total time=   0.3s\n",
      "[CV 3/10; 65/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 65/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.714 total time=   0.3s\n",
      "[CV 4/10; 65/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 65/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.714 total time=   0.3s\n",
      "[CV 5/10; 65/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 65/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.714 total time=   0.3s\n",
      "[CV 6/10; 65/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 65/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.710 total time=   0.3s\n",
      "[CV 7/10; 65/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 65/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.704 total time=   0.3s\n",
      "[CV 8/10; 65/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 65/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.722 total time=   0.3s\n",
      "[CV 9/10; 65/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 65/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.709 total time=   0.3s\n",
      "[CV 10/10; 65/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 65/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.707 total time=   0.3s\n",
      "[CV 1/10; 66/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 66/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.701 total time=   0.3s\n",
      "[CV 2/10; 66/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 66/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.716 total time=   0.3s\n",
      "[CV 3/10; 66/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 66/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.714 total time=   0.4s\n",
      "[CV 4/10; 66/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 66/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.711 total time=   0.3s\n",
      "[CV 5/10; 66/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 66/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.713 total time=   0.4s\n",
      "[CV 6/10; 66/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 66/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.709 total time=   0.5s\n",
      "[CV 7/10; 66/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 66/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.705 total time=   0.3s\n",
      "[CV 8/10; 66/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 66/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.720 total time=   0.3s\n",
      "[CV 9/10; 66/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 66/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.709 total time=   0.3s\n",
      "[CV 10/10; 66/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 66/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.702 total time=   0.3s\n",
      "[CV 1/10; 67/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 67/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.703 total time=   1.8s\n",
      "[CV 2/10; 67/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 67/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.715 total time=   1.4s\n",
      "[CV 3/10; 67/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 67/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.715 total time=   1.4s\n",
      "[CV 4/10; 67/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 67/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.711 total time=   1.3s\n",
      "[CV 5/10; 67/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008820 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 67/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.713 total time=   1.4s\n",
      "[CV 6/10; 67/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 67/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.709 total time=   1.3s\n",
      "[CV 7/10; 67/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 67/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.704 total time=   1.4s\n",
      "[CV 8/10; 67/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 67/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.720 total time=   1.4s\n",
      "[CV 9/10; 67/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 67/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.708 total time=   1.4s\n",
      "[CV 10/10; 67/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 67/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.703 total time=   1.5s\n",
      "[CV 1/10; 68/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 68/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.702 total time=   1.7s\n",
      "[CV 2/10; 68/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 68/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.715 total time=   1.6s\n",
      "[CV 3/10; 68/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 68/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.713 total time=   1.7s\n",
      "[CV 4/10; 68/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 68/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.708 total time=   1.6s\n",
      "[CV 5/10; 68/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 68/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.708 total time=   1.6s\n",
      "[CV 6/10; 68/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 68/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.709 total time=   1.6s\n",
      "[CV 7/10; 68/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 68/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.702 total time=   1.6s\n",
      "[CV 8/10; 68/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 68/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.716 total time=   1.7s\n",
      "[CV 9/10; 68/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 68/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.705 total time=   1.7s\n",
      "[CV 10/10; 68/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 68/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.705 total time=   1.6s\n",
      "[CV 1/10; 69/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 69/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.699 total time=   2.0s\n",
      "[CV 2/10; 69/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 69/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.716 total time=   2.0s\n",
      "[CV 3/10; 69/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 69/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.711 total time=   2.0s\n",
      "[CV 4/10; 69/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 69/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.709 total time=   2.0s\n",
      "[CV 5/10; 69/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 69/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.708 total time=   2.0s\n",
      "[CV 6/10; 69/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 69/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.706 total time=   2.0s\n",
      "[CV 7/10; 69/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 69/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.704 total time=   2.2s\n",
      "[CV 8/10; 69/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 69/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.715 total time=   2.0s\n",
      "[CV 9/10; 69/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 69/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.708 total time=   2.0s\n",
      "[CV 10/10; 69/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 69/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.701 total time=   2.0s\n",
      "[CV 1/10; 70/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 70/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.692 total time=  12.7s\n",
      "[CV 2/10; 70/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 70/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.701 total time=  13.3s\n",
      "[CV 3/10; 70/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 70/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.701 total time=  12.4s\n",
      "[CV 4/10; 70/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 70/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.700 total time=  12.4s\n",
      "[CV 5/10; 70/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 70/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.699 total time=  12.3s\n",
      "[CV 6/10; 70/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 70/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.698 total time=  12.5s\n",
      "[CV 7/10; 70/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 70/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.696 total time=  12.5s\n",
      "[CV 8/10; 70/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 70/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.707 total time=  12.6s\n",
      "[CV 9/10; 70/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 70/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.701 total time=  12.6s\n",
      "[CV 10/10; 70/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 70/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.691 total time=  12.7s\n",
      "[CV 1/10; 71/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 71/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.688 total time=  15.2s\n",
      "[CV 2/10; 71/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 71/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.696 total time=  15.4s\n",
      "[CV 3/10; 71/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 71/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.692 total time=  15.4s\n",
      "[CV 4/10; 71/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 71/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.689 total time=  15.7s\n",
      "[CV 5/10; 71/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 71/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.693 total time=  16.5s\n",
      "[CV 6/10; 71/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 71/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.691 total time=  16.0s\n",
      "[CV 7/10; 71/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 71/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.692 total time=  15.9s\n",
      "[CV 8/10; 71/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 71/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.694 total time=  16.3s\n",
      "[CV 9/10; 71/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 71/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.693 total time=  16.1s\n",
      "[CV 10/10; 71/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 71/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.683 total time=  16.2s\n",
      "[CV 1/10; 72/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 72/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.682 total time=  20.5s\n",
      "[CV 2/10; 72/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 72/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.687 total time=  20.0s\n",
      "[CV 3/10; 72/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 72/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.685 total time=  19.9s\n",
      "[CV 4/10; 72/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 72/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.688 total time=  19.4s\n",
      "[CV 5/10; 72/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 72/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.692 total time=  18.7s\n",
      "[CV 6/10; 72/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 72/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.684 total time=  18.1s\n",
      "[CV 7/10; 72/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 72/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.687 total time=  17.3s\n",
      "[CV 8/10; 72/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 72/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.684 total time=  17.0s\n",
      "[CV 9/10; 72/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 72/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.688 total time=  16.3s\n",
      "[CV 10/10; 72/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 72/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=50, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.683 total time=  15.9s\n",
      "[CV 1/10; 73/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 73/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.703 total time=   0.2s\n",
      "[CV 2/10; 73/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 73/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.715 total time=   0.2s\n",
      "[CV 3/10; 73/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 73/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.714 total time=   0.2s\n",
      "[CV 4/10; 73/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 73/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.710 total time=   0.2s\n",
      "[CV 5/10; 73/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 73/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.714 total time=   0.2s\n",
      "[CV 6/10; 73/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 73/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.709 total time=   0.2s\n",
      "[CV 7/10; 73/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 73/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.705 total time=   0.2s\n",
      "[CV 8/10; 73/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 73/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.720 total time=   0.2s\n",
      "[CV 9/10; 73/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 73/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.710 total time=   0.2s\n",
      "[CV 10/10; 73/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 73/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=5;, score=0.706 total time=   0.2s\n",
      "[CV 1/10; 74/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 74/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.703 total time=   0.3s\n",
      "[CV 2/10; 74/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 74/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.715 total time=   0.3s\n",
      "[CV 3/10; 74/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 74/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.714 total time=   0.3s\n",
      "[CV 4/10; 74/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 74/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.714 total time=   0.3s\n",
      "[CV 5/10; 74/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 74/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.714 total time=   0.3s\n",
      "[CV 6/10; 74/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 74/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.710 total time=   0.3s\n",
      "[CV 7/10; 74/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 74/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.704 total time=   0.3s\n",
      "[CV 8/10; 74/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 74/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.722 total time=   0.3s\n",
      "[CV 9/10; 74/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 74/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.709 total time=   0.3s\n",
      "[CV 10/10; 74/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 74/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=7;, score=0.707 total time=   0.3s\n",
      "[CV 1/10; 75/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 75/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.701 total time=   0.3s\n",
      "[CV 2/10; 75/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 75/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.716 total time=   0.3s\n",
      "[CV 3/10; 75/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 75/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.714 total time=   0.4s\n",
      "[CV 4/10; 75/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 75/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.711 total time=   0.3s\n",
      "[CV 5/10; 75/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 75/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.713 total time=   0.3s\n",
      "[CV 6/10; 75/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 75/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.709 total time=   0.3s\n",
      "[CV 7/10; 75/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 75/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.705 total time=   0.3s\n",
      "[CV 8/10; 75/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 75/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.720 total time=   0.3s\n",
      "[CV 9/10; 75/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 75/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.709 total time=   0.3s\n",
      "[CV 10/10; 75/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 75/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=100, lightgbm__num_leaves=10;, score=0.702 total time=   0.3s\n",
      "[CV 1/10; 76/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 76/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.703 total time=   1.5s\n",
      "[CV 2/10; 76/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 76/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.715 total time=   1.3s\n",
      "[CV 3/10; 76/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 76/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.715 total time=   1.3s\n",
      "[CV 4/10; 76/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 76/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.711 total time=   1.4s\n",
      "[CV 5/10; 76/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 76/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.713 total time=   1.4s\n",
      "[CV 6/10; 76/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 76/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.709 total time=   1.3s\n",
      "[CV 7/10; 76/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 76/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.704 total time=   1.4s\n",
      "[CV 8/10; 76/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 76/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.720 total time=   1.5s\n",
      "[CV 9/10; 76/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 76/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.708 total time=   1.4s\n",
      "[CV 10/10; 76/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 76/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=5;, score=0.703 total time=   1.4s\n",
      "[CV 1/10; 77/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 77/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.702 total time=   1.6s\n",
      "[CV 2/10; 77/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 77/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.715 total time=   1.6s\n",
      "[CV 3/10; 77/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 77/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.713 total time=   1.6s\n",
      "[CV 4/10; 77/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 77/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.708 total time=   1.6s\n",
      "[CV 5/10; 77/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 77/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.708 total time=   1.5s\n",
      "[CV 6/10; 77/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 77/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.709 total time=   1.6s\n",
      "[CV 7/10; 77/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 77/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.702 total time=   1.6s\n",
      "[CV 8/10; 77/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 77/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.716 total time=   1.7s\n",
      "[CV 9/10; 77/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 77/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.705 total time=   1.6s\n",
      "[CV 10/10; 77/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 77/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=7;, score=0.705 total time=   1.6s\n",
      "[CV 1/10; 78/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 78/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.699 total time=   1.8s\n",
      "[CV 2/10; 78/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 78/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.716 total time=   1.8s\n",
      "[CV 3/10; 78/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 78/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.711 total time=   1.9s\n",
      "[CV 4/10; 78/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 78/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.709 total time=   1.8s\n",
      "[CV 5/10; 78/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 78/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.708 total time=   2.0s\n",
      "[CV 6/10; 78/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 78/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.706 total time=   2.2s\n",
      "[CV 7/10; 78/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001799 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 78/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.704 total time=   1.9s\n",
      "[CV 8/10; 78/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 78/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.715 total time=   1.8s\n",
      "[CV 9/10; 78/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 78/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.708 total time=   1.9s\n",
      "[CV 10/10; 78/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 78/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=1000, lightgbm__num_leaves=10;, score=0.701 total time=   1.8s\n",
      "[CV 1/10; 79/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 79/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.692 total time=  11.7s\n",
      "[CV 2/10; 79/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 79/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.701 total time=  11.7s\n",
      "[CV 3/10; 79/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 79/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.701 total time=  11.5s\n",
      "[CV 4/10; 79/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 79/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.700 total time=  11.5s\n",
      "[CV 5/10; 79/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 79/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.699 total time=  11.6s\n",
      "[CV 6/10; 79/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 79/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.698 total time=  11.6s\n",
      "[CV 7/10; 79/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 79/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.696 total time=  11.4s\n",
      "[CV 8/10; 79/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 79/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.707 total time=  11.7s\n",
      "[CV 9/10; 79/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 79/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.701 total time=  11.5s\n",
      "[CV 10/10; 79/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 79/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=5;, score=0.691 total time=  11.8s\n",
      "[CV 1/10; 80/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 80/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.688 total time=  13.1s\n",
      "[CV 2/10; 80/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 80/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.696 total time=  13.3s\n",
      "[CV 3/10; 80/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 80/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.692 total time=  13.2s\n",
      "[CV 4/10; 80/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 80/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.689 total time=  13.4s\n",
      "[CV 5/10; 80/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 80/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.693 total time=  13.5s\n",
      "[CV 6/10; 80/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 80/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.691 total time=  13.4s\n",
      "[CV 7/10; 80/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 80/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.692 total time=  13.5s\n",
      "[CV 8/10; 80/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 80/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.694 total time=  13.5s\n",
      "[CV 9/10; 80/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 80/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.693 total time=  13.5s\n",
      "[CV 10/10; 80/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 80/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=7;, score=0.683 total time=  13.5s\n",
      "[CV 1/10; 81/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49878, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532800 -> initscore=0.131389\n",
      "[LightGBM] [Info] Start training from score 0.131389\n",
      "[CV 1/10; 81/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.682 total time=  16.7s\n",
      "[CV 2/10; 81/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 2/10; 81/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.687 total time=  17.0s\n",
      "[CV 3/10; 81/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 3/10; 81/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.685 total time=  17.0s\n",
      "[CV 4/10; 81/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 4/10; 81/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.688 total time=  16.5s\n",
      "[CV 5/10; 81/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2712\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 5/10; 81/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.692 total time=  17.0s\n",
      "[CV 6/10; 81/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 6/10; 81/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.684 total time=  16.8s\n",
      "[CV 7/10; 81/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 7/10; 81/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.687 total time=  17.0s\n",
      "[CV 8/10; 81/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26575, number of negative: 23304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532789 -> initscore=0.131346\n",
      "[LightGBM] [Info] Start training from score 0.131346\n",
      "[CV 8/10; 81/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.684 total time=  17.4s\n",
      "[CV 9/10; 81/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2710\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 9/10; 81/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.688 total time=  16.8s\n",
      "[CV 10/10; 81/81] START lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10\n",
      "[LightGBM] [Info] Number of positive: 26576, number of negative: 23303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 49879, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532809 -> initscore=0.131426\n",
      "[LightGBM] [Info] Start training from score 0.131426\n",
      "[CV 10/10; 81/81] END lightgbm__learning_rate=0.1, lightgbm__max_depth=100, lightgbm__n_estimators=10000, lightgbm__num_leaves=10;, score=0.683 total time=  18.5s\n",
      "[LightGBM] [Info] Number of positive: 29528, number of negative: 25893\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 55421, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532794 -> initscore=0.131366\n",
      "[LightGBM] [Info] Start training from score 0.131366\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;scaling&#x27;, RobustScaler()),\n",
       "                                       (&#x27;lightgbm&#x27;,\n",
       "                                        LGBMClassifier(n_jobs=-1,\n",
       "                                                       random_state=1))]),\n",
       "             param_grid={&#x27;lightgbm__learning_rate&#x27;: [0.0001, 0.001, 0.1],\n",
       "                         &#x27;lightgbm__max_depth&#x27;: [10, 50, 100],\n",
       "                         &#x27;lightgbm__n_estimators&#x27;: [100, 1000, 10000],\n",
       "                         &#x27;lightgbm__num_leaves&#x27;: [5, 7, 10]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;scaling&#x27;, RobustScaler()),\n",
       "                                       (&#x27;lightgbm&#x27;,\n",
       "                                        LGBMClassifier(n_jobs=-1,\n",
       "                                                       random_state=1))]),\n",
       "             param_grid={&#x27;lightgbm__learning_rate&#x27;: [0.0001, 0.001, 0.1],\n",
       "                         &#x27;lightgbm__max_depth&#x27;: [10, 50, 100],\n",
       "                         &#x27;lightgbm__n_estimators&#x27;: [100, 1000, 10000],\n",
       "                         &#x27;lightgbm__num_leaves&#x27;: [5, 7, 10]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, RobustScaler()),\n",
       "                (&#x27;lightgbm&#x27;, LGBMClassifier(n_jobs=-1, random_state=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(n_jobs=-1, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('scaling', RobustScaler()),\n",
       "                                       ('lightgbm',\n",
       "                                        LGBMClassifier(n_jobs=-1,\n",
       "                                                       random_state=1))]),\n",
       "             param_grid={'lightgbm__learning_rate': [0.0001, 0.001, 0.1],\n",
       "                         'lightgbm__max_depth': [10, 50, 100],\n",
       "                         'lightgbm__n_estimators': [100, 1000, 10000],\n",
       "                         'lightgbm__num_leaves': [5, 7, 10]},\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b546aa983e4f2780c76d67318047e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016686934733297677, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/fedorturchenko/Documents/UCY/DSC-571/dsc-571/wandb/run-20230719_182244-vfv932v1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/vfv932v1' target=\"_blank\">robust_scaling_tuning_for_better_training_fit_run_2023-07-19_18-22-44</a></strong> to <a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier' target=\"_blank\">https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/vfv932v1' target=\"_blank\">https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/vfv932v1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ea234e5f254a9c9fe08d41a99dc005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">robust_scaling_tuning_for_better_training_fit_run_2023-07-19_18-22-44</strong> at: <a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/vfv932v1' target=\"_blank\">https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/vfv932v1</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230719_182244-vfv932v1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with utils.init_wandb_run(\n",
    "    name='robust_scaling_tuning_for_better_training_fit_run',\n",
    "    model=lgb.LGBMClassifier,\n",
    "    config=config,\n",
    "    group='parameters_tuning',\n",
    "    job_type='tuning_train'\n",
    ") as run:\n",
    "    train_preds = search.predict(X_train)\n",
    "\n",
    "    train_report = parse_classification_report(\n",
    "        classification_report(y_train, train_preds, output_dict=True)\n",
    "    )\n",
    "\n",
    "    metadata = {\n",
    "        'experiment': {\n",
    "            'name': run.name,\n",
    "        },\n",
    "        'classification_report': train_report,\n",
    "        'best_params': search.best_params_,\n",
    "        'config': config\n",
    "    }\n",
    "\n",
    "    artifact = wandb.Artifact(\n",
    "        name='train_classification_report',\n",
    "        type='performance_report',\n",
    "        metadata=metadata\n",
    "    )\n",
    "    run.log_artifact(artifact)\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b26509c9f3c41b5ad7888482a420263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0167519284839121, max=1.0))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/fedorturchenko/Documents/UCY/DSC-571/dsc-571/wandb/run-20230719_182257-lmlw0b2l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/lmlw0b2l' target=\"_blank\">robust_scaling_tuning_for_better_training_fit_run_2023-07-19_18-22-57</a></strong> to <a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier' target=\"_blank\">https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/lmlw0b2l' target=\"_blank\">https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/lmlw0b2l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b93137e4cb439383540d5817049be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">robust_scaling_tuning_for_better_training_fit_run_2023-07-19_18-22-57</strong> at: <a href='https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/lmlw0b2l' target=\"_blank\">https://wandb.ai/kpmg-capstone/L-G-B-M-Classifier/runs/lmlw0b2l</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230719_182257-lmlw0b2l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with utils.init_wandb_run(\n",
    "    name='robust_scaling_tuning_for_better_training_fit_run',\n",
    "    model=lgb.LGBMClassifier,\n",
    "    config=config,\n",
    "    group='parameters_tuning',\n",
    "    job_type='tuning_test'\n",
    ") as run:\n",
    "    test_preds = search.predict(X_test)\n",
    "\n",
    "    test_report = parse_classification_report(\n",
    "        classification_report(y_test, test_preds, output_dict=True)\n",
    "    )\n",
    "\n",
    "    metadata = {\n",
    "        'experiment': {\n",
    "            'name': run.name,\n",
    "        },\n",
    "        'classification_report': test_report,\n",
    "        'best_params': search.best_params_,\n",
    "        'config': config\n",
    "    }\n",
    "\n",
    "    artifact = wandb.Artifact(\n",
    "        name='test_classification_report',\n",
    "        type='performance_report',\n",
    "        metadata=metadata\n",
    "    )\n",
    "    run.log_artifact(artifact)\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'num_leaves': 7}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{k.replace('lightgbm__', ''): search.best_params_[k] for k in search.best_params_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
